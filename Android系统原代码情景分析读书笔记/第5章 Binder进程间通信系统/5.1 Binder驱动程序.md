
## 5.1 Binder驱动程序

Binder驱动程序实现在内核空间中，它的目录结构如下：

```bash
~Android/kernel/goldfish
---- drivers
    ---- staging
        ---- android
            ---- binder.h
            ---- binder.c
```

它主要由 `binder.h` 和 `binder.c` 两个源文件组成。下面我们就开始介绍 `Binder` 驱动程序的基础知识，包括基础数据结构、初始化过程，以及设备文件 `/dev/binder `的打开（ `open` ）、内存映射（ `mmap` ）和内核缓冲区管理等操作。

### 5.1.1　基础数据结构

在 `Binder` 驱动程序中有两种类型的数据结构，其中一种是在内部使用的，另一种是在内部和外部均会使用到的。接下来，我们分别对这些数据结构进行介绍。

#### struct binder_work

`kernel/drivers/staging/android/binder.c`
```c
struct binder_work {
	struct list_head entry;
	enum {
		BINDER_WORK_TRANSACTION = 1,
		BINDER_WORK_TRANSACTION_COMPLETE,
		BINDER_WORK_NODE,
		BINDER_WORK_DEAD_BINDER,
		BINDER_WORK_DEAD_BINDER_AND_CLEAR,
		BINDER_WORK_CLEAR_DEATH_NOTIFICATION,
	} type;
};
```
结构体 `binder_work` 用来描述待处理的工作项，这些工作项有可能属于一个进程，也有会可能属于一个进程中的某一个线程。成员变量 `entry` 用来将该结构体嵌入到一个宿主结构中，成员变量 `type` 用来描述工作项的类型。根据成员变量 `type` 的取值， `Binder` 驱动程序就可以判断出一个 `binder_work` 结构体嵌入到什么类型的宿主结构中。

#### struct binder_node

`kernel/drivers/staging/android/binder.c`
```cpp
struct binder_node {
	int debug_id;
	struct binder_work work;
	union {
		struct rb_node rb_node;
		struct hlist_node dead_node;
	};
	struct binder_proc *proc;
	struct hlist_head refs;
	int internal_strong_refs;
	int local_weak_refs;
	int local_strong_refs;
	void __user *ptr;
	void __user *cookie;
	unsigned has_strong_ref : 1;
	unsigned pending_strong_ref : 1;
	unsigned has_weak_ref : 1;
	unsigned pending_weak_ref : 1;
	unsigned has_async_transaction : 1;
	unsigned accept_fds : 1;
	int min_priority : 8;
	struct list_head async_todo;
};
```
结构体 `binder_node` 用来描述一个 `Binder` 实体对象。每一个 `Service` 组件在 `Binder` 驱动程序中都对应有一个 `Binder` 实体对象，用来描述它在内核中的状态。 `Binder` 驱动程序通过强引用计数和弱引用计数技术来维护它们的生命周期。

成员变量 `proc` 指向一个 `Binder` 实体对象的宿主进程。在 `Binder` 驱动程序中，这些宿主进程通过一个 `binder_proc` 结构体来描述。宿主进程使用一个红黑树来维护它内部所有的 `Binder` 实体对象，而每一个 `Binder` 实体对象的成员变量 `rb_node` 就正好是这个红黑树中的一个节点。如果一个 `Binder` 实体对象的宿主进程已经死亡了，那么这个 `Binder` 实体对象就会通过它的成员变量 `dead_node` 保存在一个全局的 `hash` 列表中。

由于一个 `Binder` 实体对象可能会同时被多个 `Client` 组件引用，因此， `Binder` 驱动程序就使用结构体 `binder_ref` 来描述这些引用关系，并且将引用了同一个 `Binder` 实体对象的所有引用都保存在一个 `hash` 列表中。这个 `hash` 列表通过 `Binder` 实体对象的成员变量 `refs` 来描述，而 `Binder` 驱动程序通过这个成员变量就可以知道有哪些 `Client` 组件引用了同一个 `Binder` 实体对象。

成员变量 `internal_strong_refs` 和 `local_strong_refs` 均是用来描述一个 `Binder` 实体对象的强引用计数，而成员变量 `local_weak_refs` 用来描述一个 `Binder` 实体对象的弱引用计数。当一个 `Binder` 实体对象请求一个 `Service` 组件来执行某一个操作时，会增加该 `Service` 组件的强引用计数或者弱引用计数，相应地， `Binder` 实体对象会将其成员变量 `has_strong_ref` 和 `has_weak_ref` 的值设置为 `1` 。当一个 `Service` 组件完成一个 `Binder` 实体对象所请求的操作之后， `Binder` 实体对象就会请求减少该 `Service` 组件的强用计数或者弱引用计数。 `Binder` 实体对象在请求一个 `Service` 组件增加或者减少强引用计数或者弱引用计数的过程中，会将其成员变量 `pending_strong_ref` 或者 `pending_weak_ref` 的值设置为 `1` ；而当该 `Service` 组件增加或者减少了强引用计数或者弱引用计数之后， `Binder` 实体对象就会将这两个成员变量的值设置为 `0` 。

成员变量 `ptr` 和 `cookie` 分别指向一个用户空间地址，它们用来描述用户空间中的一个 `Service` 组件，其中，成员变量 `cookie` 指向该 `Service` 组件的地址，而成员变量 `ptr` 指向该 `Service` 组件内部的一个引用计数对象（类型为 `weakref_impl` ）的地址。

成员变量 `has_async_transaction` 用来描述一个 `Binder` 实体对象是否正在处理一个异步事务。如果是，它的值就等于 `1` ，否则等于 `0` 。一般情况下， `Binder` 驱动程序都是将一个事务保存在一个线程的一个 `todo` 队列中的，表示要由该线程来处理该事务。每一个事务都关联着一个Binder实体对象，表示该事务的目标处理对象，即要求与该Binder实体对象对应的Service组件在指定的线程中处理该事务。然而，当Binder驱动程序发现一个事务是异步事务时，就会将它保存在目标Binder实体对象的一个异步事务队列中，这个异步事务队列就是由该目标Binder实体对象的成员变量async_todo来描述的。异步事务的定义是那些单向的进程间通信请求，即不需要等待应答的进程间通信请求，与此相对的便是同步事务。因为不需要等待应答，Binder驱动程序就认为异步事务的优先级低于同步事务，具体就表现为在同一时刻，一个Binder实体对象的所有异步事务至多只有一个会得到处理，其余的都等待在异步事务队列中，而同步事务就没有这个限制。

当一个Binder实体对象的引用计数由0变成1，或者由1变成0时，Binder驱动程序就会请求相应的Service组件增加或者减少其引用计数。这时候Binder驱动程序就会将该引用计数修改操作封装成一个类型为binder_node的工作项，即将一个Binder实体对象的成员变量work的值设置为BINDER_WORKD_NODE，并且将它添加到相应进程的todo队列中去等待处理。

成员变量min_priority表示一个Binder实体对象在处理一个来自Client进程的请求时，它所要求的处理线程，即Server进程中的一个线程，应该具备的最小线程优先级，这样就保证了与该Binder实体对象对应的Service组件可以在一个具有一定优先级的线程中处理一个来自Client进程的通信请求。一个Service组件在将自己注册到Binder驱动程序时，可以指定这个最小线程优先级，而Binder驱动程序会把这个最小线程优先级保存在相应的Binder实体对象的成员变量min_priority中。

成员变量accept_fds用来描述一个Binder实体对象是否可以接收包含有文件描述符的进程间通信数据。如果它的值等于1，就表示可以接收；否则，就表示禁止接收。当一个进程向另外一个进程发送的数据中包含有文件描述符时，Binder驱动程序就会自动在目标进程中打开一个相同的文件。基于安全性考虑，Binder驱动程序就要通过成员变量accept_fds来防止源进程在目标进程中打开文件。

最后，成员变量debug_id用来标志一个Binder实体对象的身份，它是用来帮助调试Binder驱动程序的。

#### struct binder_ref_death

`kernel/drivers/staging/android/binder.c`
```c
struct binder_ref_death {
	struct binder_work work;
	void __user *cookie;
};
```
结构体binder_ref_death用来描述一个Service组件的死亡接收通知。在正常情况下，一个Service组件被其他Client进程引用时，它是不可以销毁的。然而，Client进程是无法控制它所引用的Service组件的生命周期的，因为Service组件所在的进程可能会意外地崩溃，从而导致它意外地死亡。一个折中的处理办法是，Client进程能够在它所引用的Service组件死亡时获得通知，以便可以做出相应的处理。这时候Client进程就需要将一个用来接收死亡通知的对象的地址注册到Binder驱动程序中。

成员变量cookie用来保存负责接收死亡通知的对象的地址，成员变量work的取值为BINDER_WORK_DEAD_BINDER、BINDER_WORK_CLEAR_DEATH_NOTIFICATION或者BINDER_WORK_DEAD_BINDER_AND_CLEAR，用来标志一个具体的死亡通知类型。

Binder驱动程序决定要向一个Client进程发送一个Service组件死亡通知时，会将一个binder_ref_death结构体封装成一个工作项，并且根据实际情况来设置该结构体的成员变量work的值，最后将这个工作项添加到Client进程的todo队列中去等待处理。

在下面两种情况下，Binder驱动程序会向一个Client进程发送一个Service组件的死亡通知。

1. 当Binder驱动程序监测到一个Service组件死亡时，它就会找到该Service组件对应的Binder实体对象，然后通过Binder实体对象的成员变量refs就可以找到所有引用了它的Client进程，最后就找到这些Client进程所注册的死亡接收通知，即一个binder_ref_death结构体。这时候Binder驱动程序就会将该binder_ref_death结构体添加到Client进程的todo队列中去等待处理。在这种情况下，Binder驱动程序将死亡通知的类型设置为BINDER_WORK_DEAD_BINDER。

2. 当Client进程向Binder驱动程序注册一个死亡接收通知时，如果它所引用的Service组件已经死亡，那么Binder驱动程序就会马上发送一个死亡通知给该Client进程。在这种情况下，Binder驱动程序也会将死亡通知的类型设置为BINDER_WORK_DEAD_BINDER。

另外，当Client进程向Binder驱动程序注销一个死亡接收通知时，Binder驱动程也会向该Client进程的todo队列发送一个类型为binder_ref_death的工作项，用来表示注销结果。这时候又需要分两种情况来考虑。

1. 如果Client进程在注销一个死亡接收通知时，相应的Service组件还没有死亡，那么Binder驱动程序就会找到之前所注册的一个binder_ref_death结构体，并且将它的类型work修改为BINDER_WORK_CLEAR_DEATH_NOTIFICATION，然后再将该binder_ref_death结构体封装成一个工作项添加到该Client进程的todo队列中去等待处理。

2. 如果Client进程在注销一个死亡接收通知时，相应的Service组件已经死亡，那么Binder驱动程序就会找到之前所注册的一个binder_ref_death结构体，并且将它的类型work修改为BINDER_WORK_DEAD_BINDER_AND_CLEAR，然后再将该binder_ref_death结构体封装成一个工作项添加到该Client进程的todo队列中去等待处理。

Client进程在处理这个工作项时，通过对应的binder_ref_death结构体的成员变量work就可以区分注销结果了，即它所引用的Service组件是否已经死亡。

#### struct binder_ref

`kernel/drivers/staging/android/binder.c`
```c
struct binder_ref {
	/* Lookups needed: */
	/*   node + proc => ref (transaction) */
	/*   desc + proc => ref (transaction, inc/dec ref) */
	/*   node => refs + procs (proc exit) */
	int debug_id;
	struct rb_node rb_node_desc;
	struct rb_node rb_node_node;
	struct hlist_node node_entry;
	struct binder_proc *proc;
	struct binder_node *node;
	uint32_t desc;
	int strong;
	int weak;
	struct binder_ref_death *death;
};
```
结构体binder_ref用来描述一个Binder引用对象。每一个Client组件在Binder驱动程序中都对应有一个Binder引用对象，用来描述它在内核中的状态。Binder驱动程序通过强引用计数和弱引用计数技术来维护它们的生命周期。

成员变量node用来描述一个Binder引用对象所引用的Binder实体对象。前面在介绍结构体binder_node时提到，每一个Binder实体对象都有一个hash列表，用来保存那些引用了它的Binder引用对象，而这些Binder引用对象的成员变量node_entry正好是这个hash列表的节点。

成员变量desc是一个句柄值，或者称为描述符，它是用来描述一个Binder引用对象的。在Client进程的用户空间中，一个Binder引用对象是使用一个句柄值来描述的，因此，当Client进程的用户空间通过Binder驱动程序来访问一个Service组件时，它只需要指定一个句柄值，Binder驱动程序就可以通过该句柄值找到对应的Binder引用对象，然后再根据该Binder引用对象的成员变量node找到对应的Binder实体对象，最后就可以通过该Binder实体对象找到要访问的Service组件。

**注意**
> 一个Binder引用对象的句柄值在进程范围内是唯一的，因此，在两个不同的进程中，同一个句柄值可能代表的是两个不同的目标Service组件。

成员变量proc指向一个Binder引用对象的宿主进程。一个宿主进程使用两个红黑树来保存它内部所有的Binder引用对象，它们分别以句柄值和对应的Binder实体对象的地址来作为关键字保存这些Binder引用对象，而这些Binder引用对象的成员变量rb_node_desc和rb_node_node就正好是这两个红黑树中的节点。

成员变量strong和weak分别用来描述一个Binder引用对象的强引用计数和弱引用计数，Binder驱动程序正是通过它们来维护一个Binder引用对象的生命周期的。

成员变量death指向一个Service组件的死亡接收通知。当Client进程向Binder驱动程序注册一个它所引用的Service组件的死亡接收通知时，Binder驱动程序就会创建一个binder_ref_death结构体，然后保存在对应的Binder引用对象的成员变量death中。

最后，成员变量debug_id用来标志一个Binder引用对象的身份，它是用来帮助调试Binder驱动程序的。

#### struct binder_buffer

`kernel/drivers/staging/android/binder.c`
```c
struct binder_buffer {
	struct list_head entry; /* free and allocated entries by addesss */
	struct rb_node rb_node; /* free entry by size or allocated entry */
				/* by address */
	unsigned free : 1;
	unsigned allow_user_free : 1;
	unsigned async_transaction : 1;
	unsigned debug_id : 29;

	struct binder_transaction *transaction;

	struct binder_node *target_node;
	size_t data_size;
	size_t offsets_size;
	uint8_t data[0];
};
```
结构体binder_buffer用来描述一个内核缓冲区，它是用来在进程间传输数据的。每一个使用Binder进程间通信机制的进程在Binder驱动程序中都有一个内核缓冲区列表，用来保存Binder驱动程序为它所分配的内核缓冲区，而成员变量entry正好是这个内核缓冲区列表的一个节点。同时，进程又使用了两个红黑树来分别保存那些正在使用的内核缓冲区，以及空闲的内核缓冲区。如果一个内核缓冲区是空闲的，即它的成员变量free的值等于1，那么成员变量rb_node就是空闲内核缓冲区红黑树中的一个节点；否则，成员变量rb_node就是正在使用内核缓冲区红黑树中的一个节点。

成员变量transaction和target_node用来描述一个内核缓冲区正在交给哪一个事务以及哪一个Binder实体对象使用。Binder驱动程序使用一个binder_transaction结构体来描述一个事务，每一个事务都关联有一个目标Binder实体对象。Binder驱动程序将事务数据保存在一个内核缓冲区中，然后将它交给目标Binder实体对象处理，而目标Binder实体对象再将该内核缓冲区的内容交给相应的Service组件处理。Service组件处理完成该事务之后，如果发现传递给它的内核缓冲区的成员变量allow_user_free的值为1，那么该Service组件就会请求Binder驱动程序释放该内核缓冲区。

如果与一个内核缓冲区关联的是一个异步事务，那么Binder驱动程序就会将该内核缓冲区的成员变量async_transaction的值设置为1；否则，就将它的值设置为0。Binder驱动程序限制了分配给异步事务的内核缓冲区的大小，这样做的目的是为了保证同步事务可以优先得到内核缓冲区，以便可以快速地对该同步事务进行处理。

成员变量data指向一块大小可变的数据缓冲区，它是真正用来保存通信数据的。数据缓冲区保存的数据划分为两种类型，其中一种是普通数据，另一种是Binder对象。Binder驱动程序不关心数据缓冲区中的普通数据，但是必须要知道里面的Binder对象，因为它需要根据它们来维护内核中的Binder实体对象和Binder引用对象的生命周期。例如，如果数据缓冲区中包含了一个Binder引用，并且该数据缓冲区是传递给另外一个进程的，那么Binder驱动程序就需要为另外一个进程创建一个Binder引用对象，并且增加相应的Binder实体对象的引用计数，因为它也被另外的这个进程引用了。由于数据缓冲区中的普通数据和Binder对象是混合在一起保存的，它们之间并没有固定的顺序，因此，Binder驱动程序就需要额外的数据来找到里面的Binder对象。在数据缓冲区的后面，有一个偏移数组，它记录了数据缓冲区中每一个Binder对象在数据缓冲区中的位置。偏移数组的大小保存在成员变量offsets_size中，而数据缓冲区的大小保存在成员变量data_size中。

最后，成员变量debug_id用来标志一个内核缓冲区的身份，它是用来帮助调试Binder驱动程序的。

#### struct binder_proc

`kernel/drivers/staging/android/binder.c`
```c
struct binder_proc {
	struct hlist_node proc_node;
	struct rb_root threads;
	struct rb_root nodes;
	struct rb_root refs_by_desc;
	struct rb_root refs_by_node;
	int pid;
	struct vm_area_struct *vma;
	struct task_struct *tsk;
	struct files_struct *files;
	struct hlist_node deferred_work_node;
	int deferred_work;
	void *buffer;
	ptrdiff_t user_buffer_offset;

	struct list_head buffers;
	struct rb_root free_buffers;
	struct rb_root allocated_buffers;
	size_t free_async_space;

	struct page **pages;
	size_t buffer_size;
	uint32_t buffer_free;
	struct list_head todo;
	wait_queue_head_t wait;
	struct binder_stats stats;
	struct list_head delivered_death;
	int max_threads;
	int requested_threads;
	int requested_threads_started;
	int ready_threads;
	long default_priority;
};
```
结构体binder_proc用来描述一个正在使用Binder进程间通信机制的进程。当一个进程调用函数open来打开设备文件/dev/binder时，Binder驱动程序就会为它创建一个binder_proc结构体，并且将它保存在一个全局的hash列表中，而成员变量proc_node就正好是该hash列表中的一个节点。此外，成员变量pid、tsk和files分别指向了进程的进程组ID、任务控制块和打开文件结构体数组。

进程打开了设备文件/dev/binder之后，还必须调用函数mmap将它映射到进程的地址空间来，实际上是请求Binder驱动程序为它分配一块内核缓冲区，以便可以用来在进程间传输数据。Binder驱动程序为进程分配的内核缓冲区的大小保存在成员变量buffer_size中。这些内核缓冲区有两个地址，其中一个是内核空间地址，另外一个是用户空间地址。内核空间地址是在Binder驱动程序内部使用的，保存在成员变量buffer中，而用户空间地址是在应用程序进程内部使用的，保存在成员变量vma中。这两个地址相差一个固定的值，保存在成员变量user_buffer_offset中。这样，给定一个用户空间地址或者一个内核空间地址，Binder驱动程序就可以计算出另外一个地址的大小。

**注意**
> 这两个地址指的都是虚拟地址，它们对应的物理页面保存在成员变量pages中。成员变量pages是类型为struct page*的一个数组，数组中的每一个元素都指向一个物理页面。Binder驱动程序一开始时只为该内核缓冲区分配一个物理页面，后面不够使用时，再继续分配。

成员变量buffer指向的是一块大的内核缓冲区，Binder驱动程序为了方便对它进行管理，会将它划分成若干个小块。这些小块的内核缓冲区就是使用前面所介绍的结构体binder_buffer来描述的，它们保存在一个列表中，按照地址值从小到大的顺序来排列。成员变量buffers指向的便是该列表的头部。列表中的小块内核缓冲区有的是正在使用的，即已经分配了物理页面；有的是空闲的，即还没有分配物理页面，它们分别组织在两个红黑树中，其中，前者保存在成员变量allocated_buffers所描述的红黑树中，而后者保存在成员变量free_buffers所描述的红黑树中。此外，成员变量buffer_free保存了空闲内核缓冲区的大小，而成员变量free_async_space保存了当前可以用来保存异步事务数据的内核缓冲区的大小。

前面提到，每一个使用了Binder进程间通信机制的进程都有一个Binder线程池，用来处理进程间通信请求，这个Binder线程池是由Binder驱动程序来维护的。结构体binder_proc的成员变量threads是一个红黑树的根节点，它以线程ID作为关键字来组织一个进程的Binder线程池。进程可以调用函数ioctl将一个线程注册到Binder驱动程序中，同时，当进程没有足够的空闲线程在处理进程间通信请求时，Binder驱动程序也可以主动要求进程注册更多的线程到Binder线程池中。Binder驱动程序最多可以主动请求进程注册的线程的数量保存在成员变量max_threads中，而成员变量ready_threads表示进程当前的空闲Binder线程数目。

**注意**
> 成员变量max_threads并不是表示Binder线程池中的最大线程数目，进程本身可以主动注册任意数目的线程到Binder线程池中。Binder驱动程序每一次主动请求进程注册一个线程时，都会将成员变量requested_threads的值加1；而当进程响应这个请求之后，Binder驱动程序就会将成员变量requested_threads的值减1，而且将成员变量requested_threads_started的值加1，表示Binder驱动程序已经主动请求进程注册了多少个线程到Binder线程池中。

当进程接收到一个进程间通信请求时，Binder驱动程序就将该请求封装成一个工作项，并且加入到进程的待处理工作项队列中，这个队列使用成员变量todo来描述。Binder线程池中的空闲Binder线程会睡眠在由成员变量wait所描述的一个等待队列中，当它们的宿主进程的待处理工作项队列增加了新的工作项之后，Binder驱动程序就会唤醒这些线程，以便它们可以去处理新的工作项。成员变量default_priority的值被初始化为进程的优先级。当一个线程处理一个工作项时，它的线程优先级有可能会被设置为其宿主进程的优先级，即设置为成员变量default_priority的值，这是由于线程是代表其宿主进程来处理一个工作项的。线程在处理一个工作项时的优先级还会受到其他因素的影响，后面我们再详细描述。

一个进程内部包含了一系列的Binder实体对象和Binder引用对象，进程使用三个红黑树来组织它们，其中，成员变量nodes所描述的红黑树是用来组织Binder实体对象的，它以Binder实体对象的成员变量ptr作为关键字；而成员变量refs_by_desc和refs_by_node所描述的红黑树是用来组织Binder引用对象的，前者以Binder引用对象的成员变量desc作为关键字，而后者以Binder引用对象的成员变量node作为关键字。

成员变量deferred_work_node是一个hash列表，用来保存进程可以延迟执行的工作项。这些延迟工作项有三种类型，如下所示。

`kernel/drivers/staging/android/binder.c`
```c
enum {
	BINDER_DEFERRED_PUT_FILES    = 0x01,
	BINDER_DEFERRED_FLUSH        = 0x02,
	BINDER_DEFERRED_RELEASE      = 0x04,
};
```
Binder驱动程序为进程分配内核缓冲区时，会为这个内核缓冲区创建一个文件描述符，进程可以通过这个文件描述符将该内核缓冲区映射到自己的地址空间。当进程不再需要使用Binder进程间通信机制时，它就会通知Binder驱动程序关闭该文件描述符，并且释放之前所分配的内核缓冲区。由于这不是一个马上就需要完成的操作，因此，Binder驱动程序就会创建一个BINDER_DEFERRED_PUT_FILES类型的工作项来延迟执行该操作。

前面提到，Binder线程池中的空闲Binder线程是睡眠在一个等待队列中的，进程可以通过调用函数flush来唤醒这些线程，以便它们可以检查进程是否有新的工作项需要处理。这时候Binder驱动程序就会创建一个BINDER_DEFERRED_FLUSH类型的工作项，以便可以延迟执行唤醒空闲Binder线程的操作。

当进程不再使用Binder进程间通信机制时，它就会调用函数close来关闭设备文件/dev/binder，这时候Binder驱动程序就会释放之前为它分配的资源，例如，释放进程结构体binder_proc、Binder实体对象结构体binder_node以及Binder引用对象结构体binder_ref等。由于资源的释放操作是一个比较耗时的操作，因此，Binder驱动程序会创建一个BINDER_DEFERRED_RELEASE类型的事务来延迟执行它们。

Binder驱动程序将所有的延迟执行的工作项保存在一个hash列表中。如果一个进程有延迟执行的工作项，那么成员变量deferred_work_node就刚好是该hash列表中的一个节点，并且使用成员变量deferred_work来描述该延迟工作项的具体类型。

当一个进程所引用的Service组件死亡时，Binder驱动程序就会向该进程发送一个死亡通知。这个正在发出的死亡通知被封装成一个类型为BINDER_WORK_DEAD_BINDER或者BINDER_WORK_DEAD_BINDER_AND_CLEAR的工作项，并且保存在由成员变量delivered_death所描述的一个队列中，表示Binder驱动程序正在向进程发送的死亡通知。当进程接收到这个死亡通知之后，它便会通知Binder驱动程序，这时候Binder驱动程序就会将对应的工作项从成员变量delivered_death所描述的队列中删除。

最后，成员变量stats是用来统计进程数据的，例如，进程接收到的进程间通信请求的次数。

#### struct binder_thread

`kernel/drivers/staging/android/binder.c`
```c
struct binder_thread {
	struct binder_proc *proc;
	struct rb_node rb_node;
	int pid;
	int looper;
	struct binder_transaction *transaction_stack;
	struct list_head todo;
	uint32_t return_error; /* Write failed, return error code in read buf */
	uint32_t return_error2; /* Write failed, return error code in read */
		/* buffer. Used when sending a reply to a dead process that */
		/* we are also waiting on */
	wait_queue_head_t wait;
	struct binder_stats stats;
};
```
结构体binder_thread用来描述Binder线程池中的一个线程，其中，成员变量proc指向其宿主进程。前面在介绍进程结构体binder_proc时提到，进程结构体binder_proc使用一个红黑树来组织其Binder线程池中的线程，其中，结构体binder_thread的成员变量rb_node就是该红黑树中的一个节点。

一个Binder线程的ID和状态是通过成员变量pid和looper来描述的。线程状态的取值如下所示。

`kernel/drivers/staging/android/binder.c`
```c
enum {
	BINDER_LOOPER_STATE_REGISTERED  = 0x01,
	BINDER_LOOPER_STATE_ENTERED     = 0x02,
	BINDER_LOOPER_STATE_EXITED      = 0x04,
	BINDER_LOOPER_STATE_INVALID     = 0x08,
	BINDER_LOOPER_STATE_WAITING     = 0x10,
	BINDER_LOOPER_STATE_NEED_RETURN = 0x20
};
```
一个线程注册到Binder驱动程序时，Binder驱动程序就会为它创建一个binder_thread结构体，并且将它的状态初始化为BINDER_LOOPER_STATE_NEED_RETURN，表示该线程需要马上返回到用户空间。由于一个线程在注册为Binder线程时可能还没有准备好去处理进程间通信请求，因此，最好返回到用户空间去做准备工作。此外，当进程调用函数flush来刷新它的Binder线程池时，Binder线程池中的线程的状态也会被重置为BINDER_LOOPER_STATE_NEED_RETURN。

一个线程注册到Binder驱动程序之后，它接着就会通过BC_REGISTER_LOOPER或者BC_ENTER_LOOPER协议来通知Binder驱动程序，它可以处理进程间通信请求了，这时候Binder驱动程序就会将它的状态设置为BINDER_LOOPER_STATE_REGISTERED或者BINDER_LOOPER_STATE_ENTERED。如果一个线程是应用程序主动注册的，那么它就通过BC_ENTER_LOOPER协议来通知Binder驱动程序，它已经准备就绪处理进程间通信请求了；如果一个线程是Binder驱动程序请求创建的，那么它就通过BC_REGISTER_LOOPER协议来通知Binder驱动程序，这时候Binder驱动程序就会增加它所请求进程创建的Binder线程的数目。

当一个Binder线程处于空闲状态时，Binder驱动程序就会把它的状态设置为BINDER_LOOPER_STATE_WAITING；而当一个Binder线程退出时，它会通过BC_EXIT_LOOPER协议来通知Binder驱动程序，这时候Binder驱动程序就会将它的状态设置为BINDER_LOOPER_STATE_EXITED。在异常情况下，一个Binder线程的状态会被设置为BINDER_LOOPER_STATE_INVALID，例如，当该线程已经处于BINDER_LOOPER_STATE_REGISTERED状态时，如果它又再次通过BC_ENTER_LOOPER协议来通知Binder驱动程序它已经准备就绪了，那么Binder驱动程序就会将它的状态设置为BINDER_LOOPER_STATE_INVALID。

当一个来自Client进程的请求指定要由某一个Binder线程来处理时，这个请求就会加入到相应的binder_thread结构体的成员变量todo所表示的队列中，并且会唤醒这个线程来处理，因为这时候这个线程可能处于睡眠状态。

当Binder驱动程序决定将一个事务交给一个Binder线程处理时，它就会将该事务封装成一个binder_transaction结构体，并且将它添加到由线程结构体binder_thread的成员变量transaction_stack所描述的一个事务堆栈中。结构体binder_transaction的设计很巧妙，后面我们再详细介绍它的定义。

当一个Binder线程在处理一个事务T1并需要依赖于其他的Binder线程来处理另外一个事务T2时，它就会睡眠在由成员变量wait所描述的一个等待队列中，直到事务T2处理完成为止。

一个Binder线程在处理一个事务时，如果出现了异常情况，那么Binder驱动程序就会将相应的错误码保存在其成员变量return_error和reutrn_error2中，这时候线程就会将这些错误返回给用户空间应用程序处理。

最后，成员变量stats是用来统计Binder线程数据的，例如，Binder线程接收到的进程间通信请求的次数。

#### struct binder_transaction

`kernel/drivers/staging/android/binder.c`
```c
struct binder_transaction {
	int debug_id;
	struct binder_work work;
	struct binder_thread *from;
	struct binder_transaction *from_parent;
	struct binder_proc *to_proc;
	struct binder_thread *to_thread;
	struct binder_transaction *to_parent;
	unsigned need_reply : 1;
	/*unsigned is_dead : 1;*/ /* not used at the moment */

	struct binder_buffer *buffer;
	unsigned int	code;
	unsigned int	flags;
	long	priority;
	long	saved_priority;
	uid_t	sender_euid;
};
```
结构体binder_transaction用来描述进程间通信过程，这个过程又称为一个事务。成员变量need_reply用来区分一个事务是同步的还是异步的。同步事务需要等待对方回复，这时候它的成员变量need_reply的值就会设置为1；否则就设置为0，表示这是一个异步事务，不需要等待回复。

成员变量from指向发起事务的线程，称为源线程；成员变量to_proc和to_thread分别指向负责处理该事务的进程和线程，称为目标进程和目标线程。当Binder驱动程序为目标进程或者目标线程创建一个事务时，就会将该事务的成员变量work的值设置为BINDER_WORK_TRANSACTION，并且将它添加到目标进程或者目标线程的todo队列中去等待处理。

成员变量priority和sender_euid分别用来描述源线程的优先级和用户ID。通过这两个成员变量，目标进程或者目标线程就可以识别事务发起方的身份。

一个线程在处理一个事务时，Binder驱动程序需要修改它的线程优先级，以便满足源线程和目标Service组件的要求。Binder驱动程序在修改一个线程的优先级之前，会将它原来的线程优先级保存在一个事务结构体的成员变量saved_priority中，以便线程处理完成该事务后可以恢复原来的优先级。前面在介绍结构体binder_node时提到，目标线程在处理一个事务时，它的线程优先级不能低于目标Service组件所要求的线程优先级，而且也不能低于源线程的优先级。这时候Binder驱动程序就会将这二者中的较大值设置为目标线程的优先级。

成员变量buffer指向Binder驱动程序为该事务分配的一块内核缓冲区，它里面保存了进程间通信数据。成员变量code和flags是直接从进程间通信数据中拷贝过来的，后面在介绍结构体binder_transaction_data时，我们再详细分析。

成员变量from_parent和to_parent分别描述一个事务所依赖的另外一个事务，以及目标线程下一个需要处理的事务。假设线程A发起了一个事务T1，需要由线程B来处理；线程B在处理事务T1时，又需要线程C先处理事务T2；线程C在处理事务T2时，又需要线程A先处理事务T3。这样，事务T1就依赖于事务T2，而事务T2又依赖于事务T3，它们的关系如下：
```dotnetcli
T1 -> from_parent = T2;
T2 -> from_parent = T3;
```

对于线程A来说，它需要处理的事务有两个，分别是T1和T3，它首先要处理事务T3，然后才能处理事务T1，因此，事务T1和T3的关系如下：
```dotnetcli
T3 -> to_parent = T1;
```
考虑这样一个情景：如果线程C在发起事务T3给线程A所属的进程来处理时，Binder驱动程序选择了该进程的另外一个线程D来处理该事务，这时候会出现什么情况呢？这时候线程A就会处于空闲等待状态，什么也不能做，因为它必须要等线程D处理完成事务T3后，它才可以继续执行事务T1。在这种情况下，与其让线程A闲着，还不如把事务T3交给它来处理，这样线程D就可以去处理其他事务，提高了进程的并发性。

现在，关键的问题又来了——Binder驱动程序在分发事务T3给目标进程处理时，它是如何知道线程A属于目标进程，并且正在等待事务T3的处理结果的？当线程B在处理事务T2时，就会将事务T2放在其事务堆栈transaction_stack的最前端。这样当线程B发起事务T3给线程C处理时，Binder驱动程序就可以沿着线程B的事务堆栈transaction_stack向下遍历，直到发现事务T3的目标进程等于事务T1的目标进程时，它就知道线程A正在等待事务T3的处理结果了。

**注意**
> 线程A在处理事务T3时，Binder驱动程序会将事务T3放在其事务堆栈transaction_stack的最前端，而在此之前，该事务堆栈transaction_stack的最前端指向的是事务T1。为了能够让线程A处理完成事务T3之后，接着处理事务T1，Binder驱动程序会将事务T1保存在事务T3的成员变量to_parent中。等到线程A处理完成事务T3之后，就可以通过事务T3的成员变量to_parent找到事务T1，再将它放在线程A的事务堆栈transaction_stack的最前端了。

最后，成员变量debug_id用来标志一个事务结构体的身份，它是用来帮助调试Binder驱动程序的。

以上介绍的结构体都是在Binder驱动程序内部使用的。前面提到，应用程序进程在打开了设备文件/dev/binder之后，需要通过IO控制函数ioctl来进一步与Binder驱动程序进行交互，因此，Binder驱动程序就提供了一系列的IO控制命令来和应用程序进程通信。在这些IO控制命令中，最重要的便是BINDER_WRITE_READ命令了，它的定义如下所示。

`kernel/drivers/staging/android/binder.h`
```c
#define BINDER_WRITE_READ   		_IOWR('b', 1, struct binder_write_read)
```

IO控制命令BINDER_WRITE_READ后面所跟的参数是一个binder_write_read结构体，它的定义如下所示。

`kernel/drivers/staging/android/binder.h`
```c
struct binder_write_read {
	signed long	write_size;	/* bytes to write */
	signed long	write_consumed;	/* bytes consumed by driver */
	unsigned long	write_buffer;
	signed long	read_size;	/* bytes to read */
	signed long	read_consumed;	/* bytes consumed by driver */
	unsigned long	read_buffer;
};
```
结构体binder_write_read用来描述进程间通信过程中所传输的数据。这些数据包括输入数据和输出数据，其中，成员变量write_size、write_consumed和write_buffer用来描述输入数据，即从用户空间传输到Binder驱动程序的数据；而成员变量read_size、read_consumed和read_buffer用来描述输出数据，即从Binder驱动程序返回给用户空间的数据，它也是进程间通信结果数据。

成员变量write_buffer指向一个用户空间缓冲区的地址，里面保存的内容即为要传输到Binder驱动程序的数据。缓冲区write_buffer的大小由成员变量write_size来指定，单位是字节。成员变量write_consumed用来描述Binder驱动程序从缓冲区write_buffer中处理了多少个字节的数据。

成员变量read_buffer也是指向一个用户空间缓冲区的地址，里面保存的内容即为Binder驱动程序返回给用户空间的进程间通信结果数据。缓冲区read_buffer的大小由成员变量read_size来指定，单位是字节。成员变量read_consumed用来描述用户空间应用程序从缓冲区read_buffer中处理了多少个字节的数据。

缓冲区write_buffer和read_buffer的数据格式如图5-2所示。

![](pic/2020-11-18-19-46-30.png)

它们都是一个数组，数组的每一个元素都由一个通信协议代码及其通信数据组成。协议代码又分为两种类型，其中一种是在输入缓冲区write_buffer中使用的，称为命令协议代码，另一种是在输出缓冲区read_buffer中使用的，称为返回协议代码。命令协议代码通过BinderDriverCommandProtocol枚举值来定义，而返回协议代码通过BinderDriverReturnProtocol枚举值来定义。

命令协议代码的定义如下所示。

**BinderDriverCommandProtocol**

`kernel/drivers/staging/android/binder.h`
```cpp
enum BinderDriverCommandProtocol {
	BC_TRANSACTION = _IOW('c', 0, struct binder_transaction_data),
	BC_REPLY = _IOW('c', 1, struct binder_transaction_data),
	/*
	 * binder_transaction_data: the sent command.
	 */

	BC_ACQUIRE_RESULT = _IOW('c', 2, int),
	/*
	 * not currently supported
	 * int:  0 if the last BR_ATTEMPT_ACQUIRE was not successful.
	 * Else you have acquired a primary reference on the object.
	 */

	BC_FREE_BUFFER = _IOW('c', 3, int),
	/*
	 * void *: ptr to transaction data received on a read
	 */

	BC_INCREFS = _IOW('c', 4, int),
	BC_ACQUIRE = _IOW('c', 5, int),
	BC_RELEASE = _IOW('c', 6, int),
	BC_DECREFS = _IOW('c', 7, int),
	/*
	 * int:	descriptor
	 */

	BC_INCREFS_DONE = _IOW('c', 8, struct binder_ptr_cookie),
	BC_ACQUIRE_DONE = _IOW('c', 9, struct binder_ptr_cookie),
	/*
	 * void *: ptr to binder
	 * void *: cookie for binder
	 */

	BC_ATTEMPT_ACQUIRE = _IOW('c', 10, struct binder_pri_desc),
	/*
	 * not currently supported
	 * int: priority
	 * int: descriptor
	 */

	BC_REGISTER_LOOPER = _IO('c', 11),
	/*
	 * No parameters.
	 * Register a spawned looper thread with the device.
	 */

	BC_ENTER_LOOPER = _IO('c', 12),
	BC_EXIT_LOOPER = _IO('c', 13),
	/*
	 * No parameters.
	 * These two commands are sent as an application-level thread
	 * enters and exits the binder loop, respectively.  They are
	 * used so the binder can have an accurate count of the number
	 * of looping threads it has available.
	 */

	BC_REQUEST_DEATH_NOTIFICATION = _IOW('c', 14, struct binder_ptr_cookie),
	/*
	 * void *: ptr to binder
	 * void *: cookie
	 */

	BC_CLEAR_DEATH_NOTIFICATION = _IOW('c', 15, struct binder_ptr_cookie),
	/*
	 * void *: ptr to binder
	 * void *: cookie
	 */

	BC_DEAD_BINDER_DONE = _IOW('c', 16, void *),
	/*
	 * void *: cookie
	 */
};
```
命令协议代码BC_TRANSACTION和BC_REPLY后面跟的通信数据使用一个结构体binder_transaction_data来描述。当一个进程请求另外一个进程执行某一个操作时，源进程就使用命令协议代码BC_TRANSACTION来请求Binder驱动程序将通信数据传递到目标进程；当目标进程处理完成源进程所请求的操作之后，它就使用命令协议代码BC_REPLY来请求Binder驱动程序将结果数据传递给源进程。

命令协议代码BC_ACQUIRE_RESULT在当前的Binder驱动程序实现中不支持。

命令协议代码BC_FREE_BUFFER后面跟的通信数据是一个整数，它指向了在Binder驱动程序内部所分配的一块内核缓冲区。Binder驱动程序就是通过这个内核缓冲区将源进程的通信数据传递到目标进程的。当目标进程处理完成源进程的通信请求之后，它就会使用命令协议代码BC_FREE_BUFFER来通知Binder驱动程序释放这个内核缓冲区。

命令协议代码BC_INCREFS、BC_ACQUIRE、BC_RELEASE和BC_DECREFS后面跟的通信数据是一个整数，它描述了一个Binder引用对象的句柄值，其中，命令协议代码BC_INCREFS和BC_DECREFS分别用来增加和减少一个Binder引用对象的弱引用计数；而命令协议代码BC_ACQUIRE和BC_RELEASE分别用来增加和减少一个Binder引用对象的强引用计数。

命令协议代码BC_INCREFS_DONE和BC_ACQUIRE_DONE后面跟的通信数据使用一个结构体binder_ptr_cookie来描述。Binder驱动程序第一次增加一个Binder实体对象的强引用计数或者弱引用计数时，就会使用返回协议代码BR_ACQUIRE或者BR_INCREFS来请求对应的Server进程增加对应的Service组件的强引用计数或者弱引用计数。当Server进程处理完成这两个请求之后，就会分别使用命令协议代码BC_INCREFS_DONE和BC_ACQUIRE_DONE将操作结果返回给Binder驱动程序。

命令协议代码BC_ATTEMPT_ACQUIRE在当前的Binder驱动程序实现中不支持。

命令协议代码BC_REGISTER_LOOPER、BC_ENTER_LOOPER和BC_EXIT_LOOPER后面不需要指定通信数据。一方面，当一个线程将自己注册到Binder驱动程序之后，它接着就会使用命令协议代码BC_ENTER_LOOPER来通知Binder驱动程序，它已经准备就绪处理进程间通信请求了；另一方面，当Binder驱动程序主动请求进程注册一个新的线程到它的Binder线程池中来处理进程间通信请求之后，新创建的线程就会使用命令协议代码BC_REGISTER_LOOPER来通知Binder驱动程序，它准备就绪了。最后，当一个线程要退出时，它就使用命令协议代码BC_EXIT_LOOPER从Binder驱动程序中注销，这样它就不会再接收到进程间通信请求了。

命令协议代码BC_REQUEST_DEATH_NOTIFICATION和BC_CLEAR_DEATH_NOTIFICATION后面跟的通信数据使用一个结构体binder_ptr_cookie来描述。一方面，如果一个进程希望获得它所引用的Service组件的死亡接收通知，那么它就需要使用命令协议代码BC_REQUEST_DEATH_NOTIFICATION来向Binder驱动程序注册一个死亡接收通知；另一方面，如果一个进程想注销之前所注册的一个死亡接收通知，那么它就需要使用命令协议代码BC_CLEAR_DEATH_NOTIFICATION来向Binder驱动程序发出请求。

命令协议代码BC_DEAD_BINDER_DONE后面跟的通信数据是一个void类型的指针，指向一个死亡接收通知结构体binder_ref_death的地址。当一个进程获得一个Service组件的死亡通知时，它就会使用命令协议代码BC_DEAD_BINDER_DONE来通知Binder驱动程序，它已经处理完成该Service组件的死亡通知了。

返回协议代码的定义如下所示。

**BinderDriverReturnProtocol**

`kernel/drivers/staging/android/binder.h`
```cpp
enum BinderDriverReturnProtocol {
	BR_ERROR = _IOR('r', 0, int),
	/*
	 * int: error code
	 */

	BR_OK = _IO('r', 1),
	/* No parameters! */

	BR_TRANSACTION = _IOR('r', 2, struct binder_transaction_data),
	BR_REPLY = _IOR('r', 3, struct binder_transaction_data),
	/*
	 * binder_transaction_data: the received command.
	 */

	BR_ACQUIRE_RESULT = _IOR('r', 4, int),
	/*
	 * not currently supported
	 * int: 0 if the last bcATTEMPT_ACQUIRE was not successful.
	 * Else the remote object has acquired a primary reference.
	 */

	BR_DEAD_REPLY = _IO('r', 5),
	/*
	 * The target of the last transaction (either a bcTRANSACTION or
	 * a bcATTEMPT_ACQUIRE) is no longer with us.  No parameters.
	 */

	BR_TRANSACTION_COMPLETE = _IO('r', 6),
	/*
	 * No parameters... always refers to the last transaction requested
	 * (including replies).  Note that this will be sent even for
	 * asynchronous transactions.
	 */

	BR_INCREFS = _IOR('r', 7, struct binder_ptr_cookie),
	BR_ACQUIRE = _IOR('r', 8, struct binder_ptr_cookie),
	BR_RELEASE = _IOR('r', 9, struct binder_ptr_cookie),
	BR_DECREFS = _IOR('r', 10, struct binder_ptr_cookie),
	/*
	 * void *:	ptr to binder
	 * void *: cookie for binder
	 */

	BR_ATTEMPT_ACQUIRE = _IOR('r', 11, struct binder_pri_ptr_cookie),
	/*
	 * not currently supported
	 * int:	priority
	 * void *: ptr to binder
	 * void *: cookie for binder
	 */

	BR_NOOP = _IO('r', 12),
	/*
	 * No parameters.  Do nothing and examine the next command.  It exists
	 * primarily so that we can replace it with a BR_SPAWN_LOOPER command.
	 */

	BR_SPAWN_LOOPER = _IO('r', 13),
	/*
	 * No parameters.  The driver has determined that a process has no
	 * threads waiting to service incomming transactions.  When a process
	 * receives this command, it must spawn a new service thread and
	 * register it via bcENTER_LOOPER.
	 */

	BR_FINISHED = _IO('r', 14),
	/*
	 * not currently supported
	 * stop threadpool thread
	 */

	BR_DEAD_BINDER = _IOR('r', 15, void *),
	/*
	 * void *: cookie
	 */
	BR_CLEAR_DEATH_NOTIFICATION_DONE = _IOR('r', 16, void *),
	/*
	 * void *: cookie
	 */

	BR_FAILED_REPLY = _IO('r', 17),
	/*
	 * The the last transaction (either a bcTRANSACTION or
	 * a bcATTEMPT_ACQUIRE) failed (e.g. out of memory).  No parameters.
	 */
};
```
返回协议代码BR_ERROR后面跟的通信数据是一个整数，用来描述一个错误代码。Binder驱动程序在处理应用程序进程发出的某个请求时，如果发生了异常情况，它就会使用返回协议代码BR_ERROR来通知应用程序进程。

返回协议代码BR_OK后面不需要指定通信数据。Binder驱动程序成功处理了应用程序进程发出的某一个请求之后，它就会使用返回协议代码BR_OK来通知应用程序进程。

返回协议代码BR_TRANSACTION和BR_REPLY后面跟的通信数据使用一个结构体binder_transaction_data来描述。当一个Client进程向一个Server进程发出进程间通信请求时，Binder驱动程序就会使用返回协议代码BR_TRANSACTION通知该Server进程来处理该进程间通信请求；当Server进程处理完成该进程间通信请求之后，Binder驱动程序就会使用返回协议代码BR_REPLY将进程间通信请求结果数据返回给Client进程。

返回协议代码BR_ACQUIRE_RESULT在当前的Binder驱动程序实现中不支持。

返回协议代码BR_DEAD_REPLY后面不需要指定通信数据。Binder驱动程序在处理进程间通信请求时，如果发现目标进程或者目标线程已经死亡，它就会使用返回协议代码BR_DEAD_REPLY来通知源进程。

返回协议代码BR_TRANSACTION_COMPLETE后面不需要指定通信数据。当Binder驱动程序接收到应用程序进程给它发送的一个命令协议代码BC_TRANSACTION或者BC_REPLY时，它就会使用返回协议代码BR_TRANSACTION_COMPLETE来通知应用程序进程，该命令协议代码已经被接收，正在分发给目标进程或者目标线程处理。

返回协议代码BR_INCREFS、BR_ACQUIRE、BR_RELEASE和BR_DECREFS后面跟的通信数据使用一个结构体binder_ptr_cookie来描述，其中，命令协议代码BR_INCREFS和BR_DECREFS分别用来增加和减少一个Service组件的弱引用计数；而命令协议代码BR_ACQUIRE和BR_RELEASE分别用来增加和减少一个Service组件的强引用计数。

返回协议代码BR_ATTEMPT_ACQUIRE在当前的Binder驱动程序实现中不支持。

返回协议代码BR_NOOP后面不需要指定通信数据。Binder驱动程序使用返回协议代码BR_NOOP来通知应用程序进程执行一个空操作，它的存在是为了方便以后可以替换为返回协议代码BR_SPAWN_LOOPER。

返回协议代码BR_SPAWN_LOOPER后面不需要指定通信数据。当Binder驱动程序发现一个进程没有足够的空闲Binder线程来处理进程间通信请求时，它就会使用返回协议代码BR_SPAWN_LOOPER来通知该进程增加一个新的线程到Binder线程池中。

返回协议代码BR_FINISHED在当前的Binder驱动程序实现中不支持。

返回协议代码BR_DEAD_BINDER和BR_CLEAR_DEATH_NOTIFICATION_DONE后面跟的通信数据是一个void类型的指针，它指向一个用来接收Service组件死亡通知的对象的地址。当Binder驱动程序监测到一个Service组件的死亡事件时，它就会使用返回协议代码BR_DEAD_BINDER来通知相应的Client进程。当Client进程通知Binder驱动程序注销它之前所注册的一个死亡接收通知时，Binder驱动程序执行完成这个注销操作之后，就会使用返回协议代码BR_CLEAR_DEATH_NOTIFICATION_DONE来通知Client进程。

返回协议代码BR_FAILED_REPLY后面不需要指定通信数据。当Binder驱动程序处理一个进程发出的BC_TRANSACTION命令协议时，如果发生了异常情况，它就会使用返回协议代码BR_FAILED_REPLY来通知源进程。

介绍完Binder驱动程序提供的命令协议代码和返回协议代码之后，接下来我们继续分析这些协议所使用的两个结构体binder_ptr_cookie和binder_transaction_data的定义。

#### struct binder_ptr_cookie
`kernel/drivers/staging/android/binder.h`
```cpp
struct binder_ptr_cookie {
	void *ptr;
	void *cookie;
};
```
结构体binder_ptr_cookie用来描述一个Binder实体对象或者一个Service组件的死亡接收通知。当结构体binder_ptr_cookie描述的是一个Binder实体对象时，成员变量ptr和cookie的含义等同于前面所介绍的结构体binder_node的成员变量ptr和cookie；当结构体binder_ptr_cookie描述的是一个Service组件的死亡接收通知时，成员变量ptr指向的是一个Binder引用对象的句柄值，而成员变量cookie指向的是一个用来接收死亡通知的对象的地址。

#### struct binder_transaction_data
`kernel/drivers/staging/android/binder.h`
```cpp
struct binder_transaction_data {
	/* The first two are only used for bcTRANSACTION and brTRANSACTION,
	 * identifying the target and contents of the transaction.
	 */
	union {
		size_t	handle;	/* target descriptor of command transaction */
		void	*ptr;	/* target descriptor of return transaction */
	} target;
	void		*cookie;	/* target object cookie */
	unsigned int	code;		/* transaction command */

	/* General information about the transaction. */
	unsigned int	flags;
	pid_t		sender_pid;
	uid_t		sender_euid;
	size_t		data_size;	/* number of bytes of data */
	size_t		offsets_size;	/* number of bytes of offsets */

	/* If this transaction is inline, the data immediately
	 * follows here; otherwise, it ends with a pointer to
	 * the data buffer.
	 */
	union {
		struct {
			/* transaction data */
			const void	*buffer;
			/* offsets from buffer to flat_binder_object structs */
			const void	*offsets;
		} ptr;
		uint8_t	buf[8];
	} data;
};
```
结构体binder_transaction_data用来描述进程间通信过程中所传输的数据。
成员变量target是一个联合体，用来描述一个目标Binder实体对象或者目标Binder引用对象。如果它描述的是一个目标Binder实体对象，那么它的成员变量ptr就指向与该Binder实体对象对应的一个Service组件内部的一个弱引用计数对象（weakref_impl）的地址；如果它描述的是一个目标Binder引用对象，那么它的成员变量handle就指向该Binder引用对象的句柄值。

成员变量cookie是由应用程序进程指定的额外参数。当Binder驱动程序使用返回命令协议BR_TRANSACTION向一个Server进程发出一个进程间通信请求时，这个成员变量才有实际意义，它指向的是目标Service组件的地址。

成员变量code是由执行进程间通信的两个进程互相约定好的一个通信代码，Binder驱动程序完全不关心它的含义。

成员变量flags是一个标志值，用来描述进程间通信行为特征，它的取值如下所示。

`kernel/drivers/staging/android/binder.h`
```cpp
enum transaction_flags {
	TF_ONE_WAY	= 0x01,	/* this is a one-way call: async, no return */
	TF_ROOT_OBJECT	= 0x04,	/* contents are the component's root object */
	TF_STATUS_CODE	= 0x08,	/* contents are a 32-bit status code */
	TF_ACCEPT_FDS	= 0x10,	/* allow replies with file descriptors */
};
```
目前，只使用了TF_ONE_WAY、TF_STATUS_CODE和TF_ACCEPT_FDS这三个标志值。如果成员变量flags的TF_ONE_WAY位被设置为1，就表示这是一个异步的进程间通信过程；如果成员变量flags的TF_ACCEPT_FDS位被设置为0，就表示源进程不允许目标进程返回的结果数据中包含有文件描述符；如果成员变量flags的TF_STATUS_CODE位被设置为1，就表示成员变量data所描述的数据缓冲区的内容是一个4字节的状态码。

成员变量sender_pid和sender_euid表示发起进程间通信请求的进程的PID和UID。这两个成员变量的值是由Binder驱动程序来填写的，因此，目标进程通过这两个成员变量就可以识别出源进程的身份，以便进行安全检查。

成员变量data_size和offsets_size分别用来描述一个通信数据缓冲区以及一个偏移数组的大小。成员变量data是一个联合体，它指向一个通信数据缓冲区。当通信数据较小时，就直接使用联合体内静态分配的数组buf来传输数据；当通信数据较大时，就需要使用一块动态分配的缓冲区来传输数据了。这块动态分配的缓冲区通过一个包含两个指针的结构体来描述，即通过联合体内的成员变量ptr来描述。结构体ptr的成员变量buffer指向一个数据缓冲区，它是真正用来保存通信数据的，它的大小由前面所描述的成员变量data_size来指定。当数据缓冲区中包含有Binder对象时，那么紧跟在这个数据缓冲区的后面就会有一个偏移数组offsets，用来描述数据缓冲区中每一个Binder对象的位置。有了这个偏移数组之后，Binder驱动程序就可以正确地维护其内部的Binder实体对象和Binder引用对象的引用计数。

数据缓冲区中的每一个Binder对象都使用一个flat_binder_object结构体来描述。下面我们就通过一个例子来描述数据缓冲区的内存布局，如图5-3所示。

![](pic/2020-11-27-18-26-32.png)

在图5-3所描述的数据缓冲区中，有两个Binder对象，相应地，偏移数组的大小就等于2，里面保存的就是这两个Binder对象在数据缓冲区中的位置n1和n2。

下面我们继续分析结构体flat_binder_object的定义。

#### struct flat_binder_object
`kernel/drivers/staging/android/binder.h`
```cpp
struct flat_binder_object {
	/* 8 bytes for large_flat_header. */
	unsigned long		type;
	unsigned long		flags;

	/* 8 bytes of data. */
	union {
		void		*binder;	/* local object */
		signed long	handle;		/* remote object */
	};

	/* extra data associated with local object */
	void			*cookie;
};
```
结构体flat_binder_object除了可以描述一个Binder实体对象和一个Binder引用对象之外，还可以用来描述一个文件描述符，它们是通过成员变量type来加以区别的。

成员变量type的取值范围如下所示。

`kernel/drivers/staging/android/binder.h`
```cpp
#define B_PACK_CHARS(c1, c2, c3, c4) \
	((((c1)<<24)) | (((c2)<<16)) | (((c3)<<8)) | (c4))
#define B_TYPE_LARGE 0x85

enum {
	BINDER_TYPE_BINDER	= B_PACK_CHARS('s', 'b', '*', B_TYPE_LARGE),
	BINDER_TYPE_WEAK_BINDER	= B_PACK_CHARS('w', 'b', '*', B_TYPE_LARGE),
	BINDER_TYPE_HANDLE	= B_PACK_CHARS('s', 'h', '*', B_TYPE_LARGE),
	BINDER_TYPE_WEAK_HANDLE	= B_PACK_CHARS('w', 'h', '*', B_TYPE_LARGE),
	BINDER_TYPE_FD		= B_PACK_CHARS('f', 'd', '*', B_TYPE_LARGE),
};
```
其中，BINDER_TYPE_BINDER和BINDER_TYPE_WEAK_BINDER都是用来描述一个Binder实体对象的，前者描述的是一个强类型的Binder实体对象，而后者描述的是一个弱类型的Binder实体对象；BINDER_TYPE_HANDLE和BINDER_TYPE_WEAK_HANDLE用来描述一个Binder引用对象，前者描述的是一个强类型的Binder引用对象，而后者描述的是一个弱类型的Binder引用对象；BINDER_TYPE_FD用来描述一个文件描述符。

成员变量flags是一个标志值，只有当结构体flat_binder_object描述的是一个Binder实体对象时，它才有实际意义。目前只用到该成员变量的第0位到第8位。其中，第0位到第7位描述的是一个Binder实体对象在处理一个进程间通信请求时，它所运行在的线程应当具有的最小线程优先级；第8位用来描述一个Binder实体对象是否可以将一块包含有文件描述符的数据缓冲区传输给目标进程，如果它的值等于1，就表示允许，否则就不允许。

成员变量binder和handle组成了一个联合体。当结构体flat_binder_object描述的是一个Binder实体对象时，那么就使用成员变量binder来指向与该Binder实体对象对应的一个Service组件内部的一个弱引用计数对象（weakref_impl）的地址，并且使用成员变量cookie来指向该Service组件的地址；当结构体flat_binder_object描述的是一个Binder引用对象时，那么就使用成员变量handle来描述该Binder引用对象的句柄值。

至此，Binder驱动程序的基础数据结构就介绍完了。接下来，我们开始分析Binder设备的初始化过程。

### 5.1.2　Binder设备的初始化过程
Binder设备的初始化过程是在Binder驱动程序的初始化函数binder_init中进行的，它的实现如下所示。

`kernel/drivers/staging/android/binder.c`
```cpp
static int __init binder_init(void)
{
	int ret;

	binder_proc_dir_entry_root = proc_mkdir("binder", NULL);
	if (binder_proc_dir_entry_root)
		binder_proc_dir_entry_proc = proc_mkdir("proc", binder_proc_dir_entry_root);
	ret = misc_register(&binder_miscdev);
	if (binder_proc_dir_entry_root) {
		create_proc_read_entry("state", S_IRUGO, binder_proc_dir_entry_root, binder_read_proc_state, NULL);
		create_proc_read_entry("stats", S_IRUGO, binder_proc_dir_entry_root, binder_read_proc_stats, NULL);
		create_proc_read_entry("transactions", S_IRUGO, binder_proc_dir_entry_root, binder_read_proc_transactions, NULL);
		create_proc_read_entry("transaction_log", S_IRUGO, binder_proc_dir_entry_root, binder_read_proc_transaction_log, &binder_transaction_log);
		create_proc_read_entry("failed_transaction_log", S_IRUGO, binder_proc_dir_entry_root, binder_read_proc_transaction_log, &binder_transaction_log_failed);
	}
	return ret;
}
```
第5行到第7行代码在目标设备上创建了一个/proc/binder/proc目录，每一个使用了Binder进程间通信机制的进程在该目录下都对应有一个文件，这些文件是以进程ID来命名的，通过它们就可以读取到各个进程的Binder线程池、Binder实体对象、Binder引用对象以及内核缓冲区等信息。接下来第9行到第15行的if语句块又在/proc/binder目录下创建了五个文件state、stats、transactions、transaction_log和failed_transaction_log，通过这五个文件就可以读取到Binder驱动程序的运行状况。例如，各个命令协议（BinderDriverCommandProtocol）和返回协议（BinderDriverReturnProtocol）的请求次数、日志记录信息，以及正在执行进程间通信过程的进程信息等。

第8行调用函数misc_register来创建一个Binder设备。在前面4.2.2小节介绍日志设备的初始化过程时，我们已经分析过函数misc_register的实现了，它是用来创建一个misc类型的字符设备的。这里我们主要分析全局变量binder_miscdev的定义。

`kernel/drivers/staging/android/binder.c`
```cpp
static struct file_operations binder_fops = {
	.owner = THIS_MODULE,
	.poll = binder_poll,
	.unlocked_ioctl = binder_ioctl,
	.mmap = binder_mmap,
	.open = binder_open,
	.flush = binder_flush,
	.release = binder_release,
};

static struct miscdevice binder_miscdev = {
	.minor = MISC_DYNAMIC_MINOR,
	.name = "binder",
	.fops = &binder_fops
};
```
Binder驱动程序在目标设备上创建了一个Binder设备文件/dev/binder，这个设备文件的操作方法列表是由全局变量binder_fops指定的。全局变量binder_fops为Binder设备文件/dev/binder指定文件打开、内存映射和IO控制函数分别为binder_open、binder_mmap和binder_ioctl。

在接下来的5.1.3和5.1.4小节中，我们将详细分析函数binder_open和binder_mmap的实现；在5.6到5.9小节中，我们将结合具体的使用情景来分析函数binder_ioctl的实现。

#### 5.1.3　Binder设备文件的打开过程
一个进程在使用Binder进程间通信机制之前，首先要调用函数open打开设备文件/dev/binder来获得一个文件描述符，然后才能通过这个文件描述符来和Binder驱动程序交互，继而和其他进程执行Binder进程间通信。

从前面5.1.2小节的内容可以知道，当进程调用函数open打开设备文件/dev/binder时，Binder驱动程序中的函数binder_open就会被调用，它的实现如下所示。

`kernel/drivers/staging/android/binder.c`
```cpp
static int binder_open(struct inode *nodp, struct file *filp)
{
	struct binder_proc *proc;

	if (binder_debug_mask & BINDER_DEBUG_OPEN_CLOSE)
		printk(KERN_INFO "binder_open: %d:%d\n", current->group_leader->pid, current->pid);

	proc = kzalloc(sizeof(*proc), GFP_KERNEL);
	if (proc == NULL)
		return -ENOMEM;
	get_task_struct(current);
	proc->tsk = current;
	INIT_LIST_HEAD(&proc->todo);
	init_waitqueue_head(&proc->wait);
	proc->default_priority = task_nice(current);
	mutex_lock(&binder_lock);
	binder_stats.obj_created[BINDER_STAT_PROC]++;
	hlist_add_head(&proc->proc_node, &binder_procs);
	proc->pid = current->group_leader->pid;
	INIT_LIST_HEAD(&proc->delivered_death);
	filp->private_data = proc;
	mutex_unlock(&binder_lock);

	if (binder_proc_dir_entry_proc) {
		char strbuf[11];
		snprintf(strbuf, sizeof(strbuf), "%u", proc->pid);
		remove_proc_entry(strbuf, binder_proc_dir_entry_proc);
		create_proc_read_entry(strbuf, S_IRUGO, binder_proc_dir_entry_proc, binder_read_proc_proc, proc);
	}

	return 0;
}
```
第8行首先为进程创建一个binder_proc结构体proc，接下来第11行到第20行代码对该binder_proc结构体proc进行初始化。在初始化binder_proc结构体proc的过程中，第12行、第15行和第19行代码分别使用进程的任务控制块current、进程优先级task_nice(current)和进程组ID来初始化binder_proc结构体proc的成员变量tsk、default_priority和pid。

第18行将binder_proc结构体proc加入到一个全局hash队列binder_procs中。全局hash队列变量binder_procs的定义如下所示。

`kernel/drivers/staging/android/binder.c`
```cpp
static HLIST_HEAD(binder_procs);
```

Binder驱动程序将所有打开了设备文件/dev/binder的进程都加入到全局hash队列binder_procs中，因此，通过遍历这个hash队列就可以知道系统当前有多少个进程在使用Binder进程间通信机制。

第21行将初始化完成之后的binder_proc结构体proc保存在参数filp的成员变量private_data中。参数filp指向一个打开文件结构体，当进程调用函数open打开设备文件/dev/binder之后，内核就会返回一个文件描述符给进程，而这个文件描述符与参数filp所指向的打开文件结构体是关联在一起的。因此，当进程后面以这个文件描述符为参数调用函数mmap或者ioctl来与Binder驱动程序交互时，内核就会将与该文件描述符相关联的打开文件结构体传递给Binder驱动程序，这时候Binder驱动程序就可以通过它的成员变量private_data来获得前面在函数binder_open中为进程创建的binder_proc结构体proc。

最后，第24行到第29行的if语句块在目标设备上的/proc/binder/proc目录下创建一个以进程ID为名称的只读文件，并且以函数binder_read_proc_proc作为它的文件内容读取函数。通过读取文件/proc/binder/proc/<PID>的内容，我们就可以获得进程<PID>的Binder线程池、Binder实体对象、Binder引用对象，以及内核缓冲区等信息。

#### 5.1.4　Binder设备文件的内存映射过程
进程打开了设备文件/dev/binder之后，还必须要调用函数mmap把这个设备文件映射到进程的地址空间，然后才可以使用Binder进程间通信机制。设备文件/dev/binder对应的是一个虚拟的设备，将它映射到进程的地址空间的目的并不是对它的内容感兴趣，而是为了为进程分配内核缓冲区，以便它可以用来传输进程间通信数据。

从前面5.1.2小节的内容可以知道，当进程调用函数mmap将设备文件/dev/binder映射到自已的地址空间时，Binder驱动程序中的函数binder_mmap就会被调用。函数binder_mmap比较长，我们分两段来阅读。

`kernel/drivers/staging/android/binder.c`
```cpp
01 static int binder_mmap(struct file *filp, struct vm_area_struct *vma)
02 {
03 	int ret;
04 	struct vm_struct *area;
05 	struct binder_proc *proc = filp->private_data;
06 	const char *failure_string;
07 	struct binder_buffer *buffer;
08 
09 	if ((vma->vm_end - vma->vm_start) > SZ_4M)
10 		vma->vm_end = vma->vm_start + SZ_4M;
11 
12 	if (binder_debug_mask & BINDER_DEBUG_OPEN_CLOSE)
13 		printk(KERN_INFO
14 			"binder_mmap: %d %lx-%lx (%ld K) vma %lx pagep %lx\n",
15 			proc->pid, vma->vm_start, vma->vm_end,
16 			(vma->vm_end - vma->vm_start) / SZ_1K, vma->vm_flags,
17 			(unsigned long)pgprot_val(vma->vm_page_prot));
18 
19 	if (vma->vm_flags & FORBIDDEN_MMAP_FLAGS) {
20 		ret = -EPERM;
21 		failure_string = "bad vm_flags";
22 		goto err_bad_arg;
23 	}
24 	vma->vm_flags = (vma->vm_flags | VM_DONTCOPY) & ~VM_MAYWRITE;
25 
26 	if (proc->buffer) {
27 		ret = -EBUSY;
28 		failure_string = "already mapped";
29 		goto err_already_mapped;
30 	}
```
参数vma指向一个结构体vm_area_struct，用来描述一段虚拟地址空间。此外，第4行定义的变量area指向的是一个结构体vm_struct，这也是用来描述一段虚拟地址空间的。这两个结构体所描述的虚拟地址空间有什么区别呢？我们首先需要明确的是，结构体vm_area_struct和vm_struct所描述的虚拟地址空间是连续的，但是它们对应的物理页面是可以不连续的。在Linux内核中，一个进程可以占用的虚拟地址空间是4G，其中，0～3G是用户地址空间，3G～4G是内核地址空间。为了区分进程的用户地址空间和内核地址空间，Linux内核就分别使用结构体vm_area_struct和vm_struct来描述它们。实际上，结构体vm_struct所描述的内核地址空间范围只有（3G＋896M＋8M）～4G。那么，中间空出来的3G～（3G＋896M＋8M）是用做什么的呢？原来，这部分内核地址空间是有特殊用途的。其中，3G～（3G＋896M）的896M空间是用来映射物理内存的前896M的，它们之间有简单的线性对应关系；而（3G＋896M）～（3G＋896M＋8M）的8M空间是一个安全保护区，是用来检测非法指针的，即所有指向这8M空间的指针都是非法的【7】。

参数filp指向一个打开文件结构体，它的成员变量private_data指向的是一个进程结构体binder_proc，它是在Binder驱动程序的函数binder_open中创建的。因此，第5行可以安全地将参数filp的成员变量private_data转换为一个binder_proc结构体指针，并且保存在变量proc中。参数vma的成员变量vm_start和vm_end指定了要映射的用户地址空间范围，第9行判断它是否超过4M。如果是的话，那么第10行就将它截断为4M。从这里就可以看出，Binder驱动程序最多可以为进程分配4M内核缓冲区来传输进程间通信数据。

接下来第14行检查进程要映射的用户地址空间是否可写，其中，FORBIDDEN_MMAP_FLAGS是一个宏，它的定义如下：

`kernel/drivers/staging/android/binder.c`
```cpp
#define FORBIDDEN_MMAP_FLAGS                (VM_WRITE)
```
Binder驱动程序为进程分配的内核缓冲区在用户空间只可以读，而不可以写，因此，如果进程指定要映射的用户地址空间可写，第17行就出错返回了。

进程指定要映射的用户地址空间除了不可以写之外，也是不可以拷贝，以及禁止设置可能会执行写操作标志位的，因此，第19行代码就将参数vma的成员变量vm_flags的VM_DONTCOPY位设置为1，并且将VM_MAYWRITE位设置为0。

第21行的if语句判断进程是否重复调用函数mmap来映射设备文件/dev/binder，即binder_proc结构体proc的成员变量buffer是否已经指向一块内核缓冲区。如果是，第24行就出错返回了。

函数binder_mmap接下来就开始为进程分配内核缓冲区了，如下所示。

`kernel/drivers/staging/android/binder.c`
```cpp
32 	area = get_vm_area(vma->vm_end - vma->vm_start, VM_IOREMAP);
33 	if (area == NULL) {
34 		ret = -ENOMEM;
35 		failure_string = "get_vm_area";
36 		goto err_get_vm_area_failed;
37 	}
38 	proc->buffer = area->addr;
39 	proc->user_buffer_offset = vma->vm_start - (uintptr_t)proc->buffer;
40 
41 #ifdef CONFIG_CPU_CACHE_VIPT
42 	if (cache_is_vipt_aliasing()) {
43 		while (CACHE_COLOUR((vma->vm_start ^ (uint32_t)proc->buffer))) {
44 			printk(KERN_INFO "binder_mmap: %d %lx-%lx maps %p bad alignment\n", proc->pid, vma->vm_start, vma->vm_end, proc->buffer);
45 			vma->vm_start += PAGE_SIZE;
46 		}
47 	}
48 #endif
49 	proc->pages = kzalloc(sizeof(proc->pages[0]) * ((vma->vm_end - vma->vm_start) / PAGE_SIZE), GFP_KERNEL);
50 	if (proc->pages == NULL) {
51 		ret = -ENOMEM;
52 		failure_string = "alloc page array";
53 		goto err_alloc_pages_failed;
54 	}
55 	proc->buffer_size = vma->vm_end - vma->vm_start;
56 
57 	vma->vm_ops = &binder_vm_ops;
58 	vma->vm_private_data = proc;
59 
60 	if (binder_update_page_range(proc, 1, proc->buffer, proc->buffer + PAGE_SIZE, vma)) {
61 		ret = -ENOMEM;
62 		failure_string = "alloc small buf";
63 		goto err_alloc_small_buf_failed;
64 	}
65 	buffer = proc->buffer;
66 	INIT_LIST_HEAD(&proc->buffers);
67 	list_add(&buffer->entry, &proc->buffers);
68 	buffer->free = 1;
69 	binder_insert_free_buffer(proc, buffer);
70 	proc->free_async_space = proc->buffer_size / 2;
71 	barrier();
72 	proc->files = get_files_struct(current);
73 	proc->vma = vma;
74 
75 	/*printk(KERN_INFO "binder_mmap: %d %lx-%lx maps %p\n", proc->pid, vma->vm_start, vma->vm_end, proc->buffer);*/
76 	return 0;
77 
78 err_alloc_small_buf_failed:
79 	kfree(proc->pages);
80 	proc->pages = NULL;
81 err_alloc_pages_failed:
82 	vfree(proc->buffer);
83 	proc->buffer = NULL;
84 err_get_vm_area_failed:
85 err_already_mapped:
86 err_bad_arg:
87 	printk(KERN_ERR "binder_mmap: %d %lx-%lx %s failed %d\n", proc->pid, vma->vm_start, vma->vm_end, failure_string, ret);
88 	return ret;
89 }
```
第26行调用函数get_vm_area在进程的内核地址空间中分配一段大小为(vma->vm_end-vma->vm_start)的空间。如果分配成功，就把它的起始地址以及大小保存在proc->buffer和proc->buffer_size中，并且指定它的打开和关闭函数为binder_vma_open和binder_vma_close。

`kernel/drivers/staging/android/binder.c`
```cpp
static struct vm_operations_struct binder_vm_ops = {
	.open = binder_vma_open,
	.close = binder_vma_close,
};
```
第33行计算要映射的用户空间起始地址与前面获得的内核空间起始地址的差值，并且保存在proc->user_buffer_offset中。Binder驱动程序为进程分配的内核缓冲区有两个地址，其中一个是用户空间地址，由参数vma所指向的一个vm_area_struct结构体来描述；另一个是内核空间地址，由变量area所指向的一个vm_struct结构体来描述。进程通过用户空间地址来访问这块内核缓冲区的内容，而Binder驱动程序通过内核空间地址来访问这块内核缓冲区的内容。由于它们是连续的，并且起始地址相差一个固定值，因此，只要知道其中的一个地址，就可以方便地计算出另外一个地址。

函数接下来就要为进程要映射的虚拟地址空间vma和area分配物理页面了，即分配内核缓冲区。第37行首先创建了一个物理页面结构体指针数组，大小为(vma->vm_end-vma->vm_start)/PAGE_SIZE，即每一页虚拟地址空间都对应有一个物理页面，并且将该数组的地址保存在proc->pages中。在Linux内核中，一个物理页面的大小为PAGE_SIZE。PAGE_SIZE是一个宏，一般定义为4K。第48行接着调用函数binder_update_page_range来为虚拟地址空间area分配一个物理页面，对应的内核地址空间为proc->buffer～(proc->buffer+PAGE_SIZE)。这个物理页面分配成功之后，第53行到第55行代码就使用一个binder_buffer结构体buffer来描述它，并且将它加入到进程结构体proc的内核缓冲区列表buffers中。由于这个物理页面是空闲的，因此，第57行继续调用函数binder_insert_free_buffer将它加入到进程结构体proc的空闲内核缓冲区红黑树free_buffers中。最后，第58行将进程最大可用于异步事务的内核缓冲区大小设置为总的内核缓冲区大小的一半，这样就可以防止异步事务消耗过多的内核缓冲区，从而影响同步事务的执行。

下面我们继续分析函数binder_update_page_range和binder_insert_free_buffer的实现。

函数binder_update_page_range的作用是为一段指定的虚拟地址空间分配或者释放物理页面，它的实现如下所示。

`kernel/drivers/staging/android/binder.c`
```cpp
01 static int binder_update_page_range(struct binder_proc *proc, int allocate,
02 	void *start, void *end, struct vm_area_struct *vma)
03 {
04 	void *page_addr;
05 	unsigned long user_page_addr;
06 	struct vm_struct tmp_area;
07 	struct page **page;
08 	struct mm_struct *mm;
09 
10 	if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
11 		printk(KERN_INFO "binder: %d: %s pages %p-%p\n",
12 		       proc->pid, allocate ? "allocate" : "free", start, end);
13 
14 	if (end <= start)
15 		return 0;
16 
17 	if (vma)
18 		mm = NULL;
19 	else
20 		mm = get_task_mm(proc->tsk);
21 
22 	if (mm) {
23 		down_write(&mm->mmap_sem);
24 		vma = proc->vma;
25 	}
26 
27 	if (allocate == 0)
28 		goto free_range;
29 
30 	if (vma == NULL) {
31 		printk(KERN_ERR "binder: %d: binder_alloc_buf failed to "
32 		       "map pages in userspace, no vma\n", proc->pid);
33 		goto err_no_vma;
34 	}
35 
36 	for (page_addr = start; page_addr < end; page_addr += PAGE_SIZE) {
37 		int ret;
38 		struct page **page_array_ptr;
39 		page = &proc->pages[(page_addr - proc->buffer) / PAGE_SIZE];
40 
41 		BUG_ON(*page);
42 		*page = alloc_page(GFP_KERNEL | __GFP_ZERO);
43 		if (*page == NULL) {
44 			printk(KERN_ERR "binder: %d: binder_alloc_buf failed "
45 			       "for page at %p\n", proc->pid, page_addr);
46 			goto err_alloc_page_failed;
47 		}
48 		tmp_area.addr = page_addr;
49 		tmp_area.size = PAGE_SIZE + PAGE_SIZE /* guard page? */;
50 		page_array_ptr = page;
51 		ret = map_vm_area(&tmp_area, PAGE_KERNEL, &page_array_ptr);
52 		if (ret) {
53 			printk(KERN_ERR "binder: %d: binder_alloc_buf failed "
54 			       "to map page at %p in kernel\n",
55 			       proc->pid, page_addr);
56 			goto err_map_kernel_failed;
57 		}
58 		user_page_addr =
59 			(uintptr_t)page_addr + proc->user_buffer_offset;
60 		ret = vm_insert_page(vma, user_page_addr, page[0]);
61 		if (ret) {
62 			printk(KERN_ERR "binder: %d: binder_alloc_buf failed "
63 			       "to map page at %lx in userspace\n",
64 			       proc->pid, user_page_addr);
65 			goto err_vm_insert_page_failed;
66 		}
67 		/* vm_insert_page does not seem to increment the refcount */
68 	}
69 	if (mm) {
70 		up_write(&mm->mmap_sem);
71 		mmput(mm);
72 	}
73 	return 0;
74 
75 free_range:
76 	for (page_addr = end - PAGE_SIZE; page_addr >= start;
77 	     page_addr -= PAGE_SIZE) {
78 		page = &proc->pages[(page_addr - proc->buffer) / PAGE_SIZE];
79 		if (vma)
80 			zap_page_range(vma, (uintptr_t)page_addr +
81 				proc->user_buffer_offset, PAGE_SIZE, NULL);
82 err_vm_insert_page_failed:
83 		unmap_kernel_range((unsigned long)page_addr, PAGE_SIZE);
84 err_map_kernel_failed:
85 		__free_page(*page);
86 		*page = NULL;
87 err_alloc_page_failed:
88 		;
89 	}
90 err_no_vma:
91 	if (mm) {
92 		up_write(&mm->mmap_sem);
93 		mmput(mm);
94 	}
95 	return -ENOMEM;
96 }
```
第一个参数proc指向要操作的目标进程；第二个参数allocate的值如果等于0，就表示要释放物理页面，否则就表示要分配物理页面；第三参数start和第四个参数end指定了要操作的内核地址空间的开始地址和结束地址；第五个参数vma指向要映射的用户地址空间。第12行到第20行代码判断参数vma是否指向一个空的用户地址空间。如果是，就从目标进程proc的成员变量vma来获得要映射的用户地址空间。

第22行的if语句判断是要为内核地址空间start～end分配物理页面还是释放物理页面。如果是分配物理页面，就执行第27行到第46行的for循环；否则，就执行第55行到第68行的for循环。

我们首先分析物理内存的分配过程。由于内核地址空间start～end可能包含了多个页面，因此，第27行到第46行通过一个for循环来依次为每一个虚拟地址空间页面分配一个物理页面。第30行首先从目标进程proc的物理页面结构体指针数组pages中获得一个与内核地址空间page_addr～(page_addr+PAGE_SIZE)对应的物理页面指针，接着第33行就调用函数alloc_page为该内核地址空间分配一个物理页面。物理页面分配成功之后，接下来就要分别映射到对应的内核地址空间和用户地址空间。其中，第36行到第39行代码用来映射内核地址空间，而第42行到第44行代码用来映射用户地址空间。

**注意**

> 在映射内核地址空间时，第37行将要映射的内核地址空间大小设置为两个页面，即用一个物理页面来映射两个内核地址空间页面。为什么要这样做呢？原来，Linux内核规定，在（3G＋896M＋8M）～4G范围内的任意一块内核地址空间都必须要在后面保留一块空的地址空间来作为安全保护区，用来检测非法指针。因此，第37行就在内核地址空间page_addr～(page_addr+PAGE_SIZE)的后面保留了大小为一页的安全保护区。另外一个需要注意的地方是，第43行将内核地址page_addr加上一个偏移值之后，就可以得到与它对应的用户空间地址，这个偏移值保存在目标进程结构体proc的成员变量user_buffer_offset中，它是在前面介绍的函数binder_mmap中设置的。

接着再分析物理页面的释放过程。同样是由于内核地址空间start～end可能包含了多个页面，因此，第55行到第68行通过一个for循环来依次为每一个虚拟地址空间页面释放物理页面。第57行首先从目标进程proc的物理页面结构体指针数组pages中获得一个与内核地址空间page_addr～(page_addr+PAGE_SIZE)对应的物理页面指针，接着第59行和第62行分别调用函数zap_page_range和unmap_kernel_range来解除该物理页面在用户地址空间和内核地址空间的映射，最后第64行就调用函数＿free_page来释放该物理页面。

至此，函数binder_update_page_range的实现就分析完成了。接下来，我们继续分析函数binder_insert_free_buffer的实现，它的作用是将一个空闲的内核缓冲区加入到进程的空闲内核缓冲区红黑树中，如下所示。

`kernel/drivers/staging/android/binder.c`
```cpp
01 static void binder_insert_free_buffer(
02 	struct binder_proc *proc, struct binder_buffer *new_buffer)
03 {
04 	struct rb_node **p = &proc->free_buffers.rb_node;
05 	struct rb_node *parent = NULL;
06 	struct binder_buffer *buffer;
07 	size_t buffer_size;
08 	size_t new_buffer_size;
09 
10 	BUG_ON(!new_buffer->free);
11 
12 	new_buffer_size = binder_buffer_size(proc, new_buffer);
13 
14 	if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
15 		printk(KERN_INFO "binder: %d: add free buffer, size %zd, "
16 		       "at %p\n", proc->pid, new_buffer_size, new_buffer);
17 
18 	while (*p) {
19 		parent = *p;
20 		buffer = rb_entry(parent, struct binder_buffer, rb_node);
21 		BUG_ON(!buffer->free);
22 
23 		buffer_size = binder_buffer_size(proc, buffer);
24 
25 		if (new_buffer_size < buffer_size)
26 			p = &parent->rb_left;
27 		else
28 			p = &parent->rb_right;
29 	}
30 	rb_link_node(&new_buffer->rb_node, parent, p);
31 	rb_insert_color(&new_buffer->rb_node, &proc->free_buffers);
32 }
```
在前面的5.1.1小节中介绍结构体binder_proc时提到，它的成员变量free_buffers用来描述一个红黑树，它按照大小来组织进程中的空闲内核缓冲区。因此，在将内核缓冲区new_buffer加入到目标进程proc的空闲内缓冲区红黑树中之前，第12行首先调用函数binder_buffer_size来计算它的大小。

函数binder_buffer_size的实现如下所示。

```cpp
1 static size_t binder_buffer_size(
2 	struct binder_proc *proc, struct binder_buffer *buffer)
3 {
4 	if (list_is_last(&buffer->entry, &proc->buffers))
5 		return proc->buffer + proc->buffer_size - (void *)buffer->data;
6 	else
7 		return (size_t)list_entry(buffer->entry.next,
8 			struct binder_buffer, entry) - (size_t)buffer->data;
9 }
```
使用结构体binder_buffer描述的内核缓冲区由两块数据组成，其中一个是元数据块，用来描述内核缓冲区本身；另一个是有效数据块，用来保存真正的事务数据。一个内核缓冲区的大小指的是其有效数据块的大小。

计算一个内核缓冲区binder_buffer的大小时，需要考虑它在进程内核缓冲区列表buffers中的位置。如果它是列表中的最后一个元素，即第4行的if语句为true，那么它所描述的内核缓冲区的有效数据块就从它的成员变量data开始，一直到Binder驱动程序为进程所分配的一块连续内核地址空间的末尾。因此，第5行就首先计算Binder驱动程序为进程proc所分配的内核地址空间的末尾地址，然后再减去内核缓冲区buffer的成员变量data的地址，最后就可以得到内核缓冲区buffer的有效数据块的大小了，如图5-4所示。

![图5-4　位于末尾的内核缓冲区的内存布局](pic/2020-11-28-16-06-15.png)

如果内核缓冲区buffer不是进程内核缓冲区列表的最后一个元素，即函数第4行的if语句为false，那么它的大小等于下一个内核缓冲区的起始地址，再减去它的成员变量data的地址，如图5-5所示。

![图5-5　位于开头或者中间的内核缓冲区的内存布局](pic/2020-11-28-16-06-52.png)

回到函数binder_insert_free_buffer中，得到内核缓冲区new_buffer的大小之后，接下来第16行到第27行的while循环就在目标进程proc的空闲内核缓冲区红黑树free_buffers中找到一个合适位置，最后第28行和第29行就调用函数rb_link_node和rb_insert_color将内核缓冲区new_buffer保存在这个位置上，这样就相当于将内核缓冲区new_buffer插入到目标进程proc的空闲内核缓冲区红黑树free_buffers中了。

至此，Binder设备文件的内存映射过程就分析完成了。一个使用Binder进程间通信机制的进程只有将Binder设备文件映射到自己的地址空间，Binder驱动程序才能够为它分配内核缓冲区，以便可以用来传输进程间通信数据。Binder驱动程序为进程分配的内核缓冲区有两个地址，其中一个是用户空间地址，另外一个是内核空间地址，它们有简单的线性对应关系，如图5-6所示。

![图5-6　Binder设备文件内存映射示意图](pic/2020-11-28-16-08-00.png)

Binder驱动程序为进程分配的内核缓冲区即为一系列物理页面，它们分别被映射到进程的用户地址空间和内核地址空间。当Binder驱动程序需要将一块数据传输给一个进程时，它就可以先把这块数据保存在为该进程所分配的一块内核缓冲区中，然后再把这块内核缓冲区的用户空间地址告诉进程，最后进程就可以访问到里面的数据了。这样做的好处便是不需要将数据从内核空间拷贝到用户空间，从而提高了数据的传输效率。

### 5.1.5　内核缓冲区管理
开始的时候，Binder驱动程序只为进程分配了一个页面的物理内存，后面会随着进程的需要而分配更多的物理内存，但是最多可以分配4M内存，这是一种按需分配的策略。物理内存的分配是以页面为单位的，但是进程一次使用的内存却不是以页面为单位的，因此，Binder驱动程序为进程维护了一个内核缓冲区池，内核缓冲区池中的每一块内存都使用一个binder_buffer结构体来描述，并且保存在一个列表中。同时，Binder驱动程序又将正在使用的内存块，即已经分配了物理页面的内存块，以及空闲的内存块，即还没有分配物理页面的内存块，分别保存在两个红黑树中。当正在使用的内存块使用完之后，Binder驱动程序就会释放它的物理页面，并且把它加入到空闲内核缓冲区红黑树中；而当进程需要新的内存块时，Binder驱动程序就从空闲内核缓冲区红黑树中分配一块合适的内核缓冲区，并且为它分配物理页面，最后交给进程来使用。

在本节接下来的内容中，我们分别介绍Binder驱动程序是如何管理进程的内核缓冲区的，包括内存缓冲区的分配、释放和查询。

#### 5.1.5.1　分配内核缓冲区

当一个进程使用命令协议BC_TRANSACTION或者BC_REPLY向另外一个进程传递数据时，Binder驱动程序就需要将这些数据从用户空间拷贝到内核空间，然后再传递给目标进程。这时候Binder驱动程序就需要在目标进程的内存池中分配出一小块内核缓冲区来保存这些数据，以便可以传递给它使用。

在Binder驱动程序中，内核缓冲区的分配操作是由函数binder_alloc_buf实现的，我们分段来阅读。

```cpp
001 static struct binder_buffer *binder_alloc_buf(struct binder_proc *proc,
002 	size_t data_size, size_t offsets_size, int is_async)
003 {
004 	struct rb_node *n = proc->free_buffers.rb_node;
005 	struct binder_buffer *buffer;
006 	size_t buffer_size;
007 	struct rb_node *best_fit = NULL;
008 	void *has_page_addr;
009 	void *end_page_addr;
010 	size_t size;
011 
012 	if (proc->vma == NULL) {
013 		printk(KERN_ERR "binder: %d: binder_alloc_buf, no vma\n",
014 		       proc->pid);
015 		return NULL;
016 	}
017 
018 	size = ALIGN(data_size, sizeof(void *)) +
019 		ALIGN(offsets_size, sizeof(void *));
020 
021 	if (size < data_size || size < offsets_size) {
022 		binder_user_error("binder: %d: got transaction with invalid "
023 			"size %zd-%zd\n", proc->pid, data_size, offsets_size);
024 		return NULL;
025 	}
026 
027 	if (is_async &&
028 	    proc->free_async_space < size + sizeof(struct binder_buffer)) {
029 		if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
030 			printk(KERN_ERR "binder: %d: binder_alloc_buf size %zd f"
031 			       "ailed, no async space left\n", proc->pid, size);
032 		return NULL;
033 	}
```
在前面的5.1.1小节中介绍命令协议BinderDriverCommandProtocol时提到，当一个进程使用命令协议BC_TRANSACTION或者BC_REPLY来与Binder驱动程序交互时，它会从用户空间传递一个binder_transaction_data结构体给Binder驱动程序，而在binder_transaction_data结构体中，有一个数据缓冲区和一个偏移数组缓冲区，这两个缓冲区的内容就是需要拷贝到目标进程的内核缓冲区中的。

了解了这个背景知识之后，我们就可以进一步说明函数的含义了。第一个参数proc用来描述目标进程；第二个参数data_size用来描述数据缓冲区的大小；第三个参数offsets_size用来描述偏移数组缓冲区的大小；第四个参数is_async用来描述所请求的内核缓冲区是用于同步事务还是异步事务的。

第14行和第15行分别将参数data_size和offsets_size对齐到一个void指针大小边界，然后将它们相加就得到要分配的内核缓冲区的大小，并且保存在变量size中。第17行的if语句检查相加后得到的size值是否发生溢出。如果是，就说明请求分配的内核缓冲区太大了，因此，第20行就直接出错返回了。

第23行和第24行的if语句检查要分配的内核缓冲区是否是用于异步事务的。如果是，就要进一步检查请求分配的内核缓冲区的大小是否大于目标进程剩余的可用于异步事务的内核缓冲区的大小。如果是，第28行就直接出错返回了。

**注意**
> 当Binder驱动程序为进程分配一个大小为size的内核缓冲区来保存数据时，还要额外分配一个binder_buffer结构体来描述这个内核缓冲区，因此，第24行在判断请求分配的内核缓冲区的大小是否大于目标进程剩余的可用于异步事务的内核缓冲区的大小时，要将变量size的值加上一个binder_buffer结构体的大小。

通过了前面合法性检查之后，我们继续往下分析函数binder_alloc_buf的实现。

```cpp
035 	while (n) {
036 		buffer = rb_entry(n, struct binder_buffer, rb_node);
037 		BUG_ON(!buffer->free);
038 		buffer_size = binder_buffer_size(proc, buffer);
039 
040 		if (size < buffer_size) {
041 			best_fit = n;
042 			n = n->rb_left;
043 		} else if (size > buffer_size)
044 			n = n->rb_right;
045 		else {
046 			best_fit = n;
047 			break;
048 		}
049 	}
050 	if (best_fit == NULL) {
051 		printk(KERN_ERR "binder: %d: binder_alloc_buf size %zd failed, "
052 		       "no address space\n", proc->pid, size);
053 		return NULL;
054 	}
055 	if (n == NULL) {
056 		buffer = rb_entry(best_fit, struct binder_buffer, rb_node);
057 		buffer_size = binder_buffer_size(proc, buffer);
058 	}
```
第30行到第44行的while循环使用最佳适配算法在目标进程的空闲内核缓冲区红黑树中检查有没有最合适的内核缓冲区可用。如果有，就将它保存在变量best_fit中；否则，第47行就直接出错返回了。

如果变量n的值等于NULL，即第50行的if语句为true，那么就说明没能从目标进程的空闲内核缓冲区红黑树中找到一块大小刚刚合适的内核缓冲区，但是找到了一块较大的内核缓冲区，因此，第51行和第52行代码就计算实际找到的内核缓冲区buffer的大小，并且保存在变量buffer_size中。

找到了一块合适的空闲内核缓冲区之后，我们继续往下分析函数binder_alloc_buf的实现。

```cpp
059 	if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
060 		printk(KERN_INFO "binder: %d: binder_alloc_buf size %zd got buff"
061 		       "er %p size %zd\n", proc->pid, size, buffer, buffer_size);
062 
063 	has_page_addr =
064 		(void *)(((uintptr_t)buffer->data + buffer_size) & PAGE_MASK);
065 	if (n == NULL) {
066 		if (size + sizeof(struct binder_buffer) + 4 >= buffer_size)
067 			buffer_size = size; /* no room for other buffers */
068 		else
069 			buffer_size = size + sizeof(struct binder_buffer);
070 	}
071 	end_page_addr =
072 		(void *)PAGE_ALIGN((uintptr_t)buffer->data + buffer_size);
073 	if (end_page_addr > has_page_addr)
074 		end_page_addr = has_page_addr;
075 	if (binder_update_page_range(proc, 1,
076 	    (void *)PAGE_ALIGN((uintptr_t)buffer->data), end_page_addr, NULL))
077 		return NULL;
```
函数第54行和第55行使用宏PAGE_MASK来计算空闲内核缓冲区buffer的结束地址所在的页面的起始地址，并且保存在变量has_page_addr中。其中，宏PAGE_MASK的定义如下所示。

`kernel/goldfish/arch/arm/include/asm/page.h`
```cpp
/* PAGE_SHIFT determines the page size */
#define PAGE_SHIFT		12
#define PAGE_SIZE		(1UL << PAGE_SHIFT)
#define PAGE_MASK		(~(PAGE_SIZE-1))
```
前面提到，如果变量n的值等于NULL，那么就说明空闲内核缓冲区buffer大于要求分配的内核缓冲区。因此，函数就需要对它进行裁剪，裁剪后就得到两块小的内核缓冲区，其中一块用来分配，另外一块要继续留在目示进程的空闲内核缓冲区红黑树中。如果裁剪后得到的第二块内核缓冲区小于或者等于4个字节，那么函数第58行就不对空闲内核缓冲区buffer进行裁剪了，而是把它都分配给目标进程来使用；如果裁剪后得到的第二块内核缓冲区大于4个字节，那么就需要将它加入到目示进程的空闲内核缓冲区红黑树中。最终将需要分配的内核缓冲区大小保存在变量buffer_size中。

得到了最终要分配的内核缓冲区的大小之后，第62行和第63行就使用宏PAGE_ALIGN将它的结束地址对齐到页面边界，并且保存在变量end_page_addr中。其中，宏PAGE_ALIGN的定义如下所示。

`kernel/include/linux/mm.h`
```cpp
/* to align the pointer to the (next) page boundary */
#define PAGE_ALIGN(addr) ALIGN(addr, PAGE_SIZE)
```
由于接下来要调用函数binder_update_page_range为前面得到的内核缓冲区分配物理页面，因此，第62行和第63行需要将要分配的内核缓冲区的结束地址对齐到页面边界。对齐之后，得到的地址end_page_addr就有可能大于原来的空闲内核缓冲区buffer的结束地址所在的页面的起始地址has_page_addr，这时候就需要将end_page_addr的值修正为has_page_addr的值，如第64行和第65行代码所示。下面我们通过三种情况来进一步说明地址end_page_addr和has_page_addr的关系。

第一种情况是空闲内核缓冲区buffer的结束地址刚好对齐到页面边界，如图5-7所示。

![图5-7　内核缓冲区buffer的结束地址对齐到页面边界](pic/2020-11-28-16-26-58.png)

这时候要分配的内核缓冲区的结束地址end_page_addr就一定等于或者小于地址has_page_addr，因此，第64行的if语句就为false。

第二种情况是空闲内核缓冲区buffer的结束地址没有对齐到页面边界，这时候要分配的内核缓冲区的结束地址end_page_addr就有可能小于或者大于地址has_page_addr，如图5-8和图5-9所示。

![图5-8　内核缓冲区buffer的结束地址没有对齐到页面边界，并且大于要分配的内核缓冲区的结束地址](pic/2020-11-28-16-27-58.png)

![图5-9　内核缓冲区buffer的结束地址没有对齐到页面边界，并且小于要分配的内核缓冲区的结束地址](pic/2020-11-28-16-28-58.png)

在图5-8中，虽然空闲内核缓冲区buffer的结束地址没有对齐到页面边界，但是由于它比要分配的内核缓冲区的结束地址大，因此，第64行的if语句也为false。

在图5-9中，当要分配的内核缓冲区大小与空闲内核缓冲区buffer大小相当时，即它们的结束地址都是在同一个页面时，就会出现地址end_page_addr大于地址has_page_addr的情况。这时候，第64行的if语句就会为true，函数就需要将要分配的内核缓冲区的结束地址end_page_addr的值设置为has_page_addr，因为要分配的内核缓冲区的结束地址end_page_addr所在的页面上肯定分配了物理页面；否则，空闲内核缓冲区buffer后面的一个内核缓冲区就会位于一个无效的物理内存中。另外，假设空闲内核缓冲区buffer是目标进程的最后一个内核缓冲区，那么我们也可以推断出一定不会出现图5-9所示的情况，因为这时候空闲内核缓冲区buffer的结束地址一定是对齐到页面边界的。

计算好要分配的内核缓冲区的结束地址所在的页面地址之后，第66行和第67行就调用函数binder_update_page_range来为它分配物理页面了。函数binder_update_page_range的实现可以参考前面5.1.4小节的内容。

为要分配的内核缓冲区分配好物理页面之后，我们继续往下分析函数binder_alloc_buf的实现。

```cpp
079 	rb_erase(best_fit, &proc->free_buffers);
080 	buffer->free = 0;
081 	binder_insert_allocated_buffer(proc, buffer);
082 	if (buffer_size != size) {
083 		struct binder_buffer *new_buffer = (void *)buffer->data + size;
084 		list_add(&new_buffer->entry, &buffer->entry);
085 		new_buffer->free = 1;
086 		binder_insert_free_buffer(proc, new_buffer);
087 	}
```
第69行首先将空闲内核缓冲区从目标进程的空闲内核缓冲区红黑树中删除，接着第71行调用函数binder_insert_allocated_buffer将前面分配的内核缓冲区加入到目标进程的已分配物理页面的内核缓冲区红黑树中。

函数binder_insert_allocated_buffer的实现如下所示。

```cpp
01 static void binder_insert_allocated_buffer(
02 	struct binder_proc *proc, struct binder_buffer *new_buffer)
03 {
04 	struct rb_node **p = &proc->allocated_buffers.rb_node;
05 	struct rb_node *parent = NULL;
06 	struct binder_buffer *buffer;
07 
08 	BUG_ON(new_buffer->free);
09 
10 	while (*p) {
11 		parent = *p;
12 		buffer = rb_entry(parent, struct binder_buffer, rb_node);
13 		BUG_ON(buffer->free);
14 
15 		if (new_buffer < buffer)
16 			p = &parent->rb_left;
17 		else if (new_buffer > buffer)
18 			p = &parent->rb_right;
19 		else
20 			BUG();
21 	}
22 	rb_link_node(&new_buffer->rb_node, parent, p);
23 	rb_insert_color(&new_buffer->rb_node, &proc->allocated_buffers);
24 }
```
在前面的5.1.1小节中介绍结构体binder_proc时提到，一个进程的已分配物理页面的内核缓冲区以它们的内核空间地址值作为关键字保存在一个红黑树allocated_buffers中，因此，第10行到第21行的while循环就首先在里面找到一个合适的位置p，接着第22行和第23行就将已经分配了物理页面的内核缓冲区new_buffer添加到目标进程的红黑树allocated_buffers中。

回到函数binder_alloc_buf中，第72行检查从原来的空闲内核缓冲区中分配出来一块新的内核缓冲区之后，是否还有剩余。如果有，第73行到第76行代码就需要将剩余的内核缓冲区封装成另外一个新的空闲内核缓冲区new_buffer，并且将它添加到目标进程的内核缓冲区列表，以及空闲内核缓冲区红黑树中。

函数binder_alloc_buf将新分配的内核缓冲区返回给调用者之前，还需要对它进行一些初始化操作，如下所示。

```cpp
088 	if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
089 		printk(KERN_INFO "binder: %d: binder_alloc_buf size %zd got "
090 		       "%p\n", proc->pid, size, buffer);
091 	buffer->data_size = data_size;
092 	buffer->offsets_size = offsets_size;
093 	buffer->async_transaction = is_async;
094 	if (is_async) {
095 		proc->free_async_space -= size + sizeof(struct binder_buffer);
096 		if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC_ASYNC)
097 			printk(KERN_INFO "binder: %d: binder_alloc_buf size %zd "
098 			       "async free %zd\n", proc->pid, size,
099 			       proc->free_async_space);
100 	}
101 
102 	return buffer;
103 }
```
第78行和第79行分别设置新分配的内核缓冲区的数据缓冲区和偏移数组缓冲区的大小。第80行设置这个新分配的内核缓冲区是否用于异步事务。如果是，即第81行的语句为true，那么第82行就相应地减少目标进程proc可用于异步事务的内核缓冲区的大小。最后，第86行将新分配的内核缓冲区返回给调用者。

至此，一个新的内核缓冲区的分配过程就分析完成了。接下来，我们继续分析内核缓冲区的释放过程。

#### 5.1.5.2　释放内核缓冲区
当一个进程处理完成Binder驱动程序给它发送的返回协议BR_TRANSACTION或者BR_REPLY之后，它就会使用命令协议BC_FREE_BUFFER来通知Binder驱动程序释放相应的内核缓冲区，以免浪费系统内存。

在Binder驱动程序中，释放内核缓冲区的操作是由函数binder_free_buf实现的，它的定义如下所示。

```cpp
01 static void binder_free_buf(
02 	struct binder_proc *proc, struct binder_buffer *buffer)
03 {
04 	size_t size, buffer_size;
05 
06 	buffer_size = binder_buffer_size(proc, buffer);
07 
08 	size = ALIGN(buffer->data_size, sizeof(void *)) +
09 		ALIGN(buffer->offsets_size, sizeof(void *));
10 	if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
11 		printk(KERN_INFO "binder: %d: binder_free_buf %p size %zd buffer"
12 		       "_size %zd\n", proc->pid, buffer, size, buffer_size);
13 
14 	BUG_ON(buffer->free);
15 	BUG_ON(size > buffer_size);
16 	BUG_ON(buffer->transaction != NULL);
17 	BUG_ON((void *)buffer < proc->buffer);
18 	BUG_ON((void *)buffer > proc->buffer + proc->buffer_size);
19 
20 	if (buffer->async_transaction) {
21 		proc->free_async_space += size + sizeof(struct binder_buffer);
22 		if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC_ASYNC)
23 			printk(KERN_INFO "binder: %d: binder_free_buf size %zd "
24 			       "async free %zd\n", proc->pid, size,
25 			       proc->free_async_space);
26 	}
27 
28 	binder_update_page_range(proc, 0,
29 		(void *)PAGE_ALIGN((uintptr_t)buffer->data),
30 		(void *)(((uintptr_t)buffer->data + buffer_size) & PAGE_MASK),
31 		NULL);
32 	rb_erase(&buffer->rb_node, &proc->allocated_buffers);
33 	buffer->free = 1;
34 	if (!list_is_last(&buffer->entry, &proc->buffers)) {
35 		struct binder_buffer *next = list_entry(buffer->entry.next,
36 						struct binder_buffer, entry);
37 		if (next->free) {
38 			rb_erase(&next->rb_node, &proc->free_buffers);
39 			binder_delete_free_buffer(proc, next);
40 		}
41 	}
42 	if (proc->buffers.next != &buffer->entry) {
43 		struct binder_buffer *prev = list_entry(buffer->entry.prev,
44 						struct binder_buffer, entry);
45 		if (prev->free) {
46 			binder_delete_free_buffer(proc, buffer);
47 			rb_erase(&prev->rb_node, &proc->free_buffers);
48 			buffer = prev;
49 		}
50 	}
51 	binder_insert_free_buffer(proc, buffer);
52 }
```
第6行计算要释放的内核缓冲区buffer的大小，并且保存在变量buffer_size中；第8行和第9行计算它的数据缓冲区，以及偏移数组缓冲区的大小之后，保存在变量size中。

第12行的if语句检查要释放的内核缓冲区buffer是否是用于异步事务的。如果是，第13行就将它所占用的大小增加到目标进程proc可用于异步事务的内核缓冲区大小free_async_space中。

第17行到第20行调用函数binder_update_page_range释放内核缓冲区buffer用来保存数据的那一部分地址空间所占用的物理页面，接着第21行将它从目标进程proc的已分配物理页面的内核缓冲区红黑树中删除。

如果要释放的内核缓冲区buffer不是目标进程proc的内核缓冲区列表中的最后一个元素，并且它前后的内核缓冲区也是空闲的，那么就需要将它们合并成一个更大的空闲内核缓冲区。第23行到第30行代码和第31行到第39行代码就是用来合并内核缓冲区buffer，以及它后面和前面的空闲内核缓冲区的。合并后得到的内核缓冲区就保存在变量buffer中，因此，第40行就调用函数binder_insert_free_buffer将它添加到目标进程proc的空闲内核缓冲区红黑树中。

合并两个连续的空闲内核缓冲区的实质是将后面一个空闲内核缓冲区删掉，然后将它所占用的地址空间追加到前面一个空闲内核缓冲区中，如图5-10所示。

![图5-10　合并两个连续的空闲内核缓冲区](pic/2020-11-28-16-34-19.png)

**注意**
> 从进程的内核缓冲区列表中删除一个内核缓冲区时，需要考虑释放用来描述将要被删除的内核缓冲区的binder_buffer结构体所占用的物理页面。将一个空闲内核缓冲区buffer从进程的内核缓冲区列表中删除是比较简单的，只要调用函数list_del(&buffer->entry)就可以了，但是释放用来描述它的binder_buffer结构体所占用的物理页面就比较复杂了，因为这个binder_buffer结构体可能横跨在两个虚拟地址页面上，如图5-11所示。

![图5-11　横跨在第N个和第N+1个虚拟地址页面上的binder_buffer结构体](pic/2020-11-28-16-35-06.png)

由于Binder驱动程序是以页面大小为单位来分配物理页面的，因此，我们在删除一个空闲缓冲区时，首先需要找到用来描述它的结构体binder_buffer所在的虚拟地址页面的地址。

Binder驱动程序提供了函数buffer_start_page和buffer_end_page来计算一个binder_buffer结构体所占用的虚拟地址页面的地址，如下所示。

```cpp
static void *buffer_start_page(struct binder_buffer *buffer)
{
	return (void *)((uintptr_t)buffer & PAGE_MASK);
}

static void *buffer_end_page(struct binder_buffer *buffer)
{
	return (void *)(((uintptr_t)(buffer + 1) - 1) & PAGE_MASK);
}
```
当一个binder_buffer结构体横跨两个虚拟地址页面时，函数buffer_start_page用来计算第一个虚拟地址页面的地址，而函数buffer_end_page用来计算第二个虚拟地址页面的地址；否则，函数buffer_start_page和buffer_end_page返回的是同一个虚拟地址页面的地址。接下来，我们只考虑一个binder_buffer结构体横跨两个虚拟地址页面的情况。

函数buffer_start_page的实现比较容易理解，把一个结构体binder_buffer的地址值与宏PAGE_MASK执行按位与操作，就得到第一个虚拟地址页面的地址了。

函数buffer_end_page的实现相对就复杂一些。由于参数buffer是一个binder_buffer结构体指针，因此，将它的值加1之后，就相当于将它往前移了一个binder_buffer结构体的大小，即得到这个binder_buffer结构体的末尾地址，最后这个末尾地址与宏PAGE_MASK执行按位与操作，就得到第二个虚拟地址页面的地址了。

以图5-11中的binder_buffer结构体为例，我们调用函数buffer_start_page和buffer_end_page来计算它横跨的两个虚拟地址页面的地址，结果如图5-12所示。

![图5-12　计算binder_buffer结构体横跨的两个虚拟地址页面的地址](pic/2020-11-28-16-37-02.png)

了解了这些基础知识之后，接下来我们开始分析用来删除binder_buffer结构体的函数binder_delete_free_buffer的实现，如下所示。

```cpp
static void binder_delete_free_buffer(
	struct binder_proc *proc, struct binder_buffer *buffer)
{
	struct binder_buffer *prev, *next = NULL;
	int free_page_end = 1;
	int free_page_start = 1;

	BUG_ON(proc->buffers.next == &buffer->entry);
	prev = list_entry(buffer->entry.prev, struct binder_buffer, entry);
	BUG_ON(!prev->free);
	if (buffer_end_page(prev) == buffer_start_page(buffer)) {
		free_page_start = 0;
		if (buffer_end_page(prev) == buffer_end_page(buffer))
			free_page_end = 0;
		if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
			printk(KERN_INFO "binder: %d: merge free, buffer %p "
			       "share page with %p\n", proc->pid, buffer, prev);
	}

	if (!list_is_last(&buffer->entry, &proc->buffers)) {
		next = list_entry(buffer->entry.next,
				  struct binder_buffer, entry);
		if (buffer_start_page(next) == buffer_end_page(buffer)) {
			free_page_end = 0;
			if (buffer_start_page(next) ==
			    buffer_start_page(buffer))
				free_page_start = 0;
			if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
				printk(KERN_INFO "binder: %d: merge free, "
				       "buffer %p share page with %p\n",
				       proc->pid, buffer, prev);
		}
	}
	list_del(&buffer->entry);
	if (free_page_start || free_page_end) {
		if (binder_debug_mask & BINDER_DEBUG_BUFFER_ALLOC)
			printk(KERN_INFO "binder: %d: merge free, buffer %p do "
			       "not share page%s%s with with %p or %p\n",
			       proc->pid, buffer, free_page_start ? "" : " end",
			       free_page_end ? "" : " start", prev, next);
		binder_update_page_range(proc, 0, free_page_start ?
			buffer_start_page(buffer) : buffer_end_page(buffer),
			(free_page_end ? buffer_end_page(buffer) :
			buffer_start_page(buffer)) + PAGE_SIZE, NULL);
	}
}
```
注意
在调用函数binder_delete_free_buffer来删除一个binder_buffer结构体buffer时，必须保证它指向的内核缓冲区不是目标进程proc的第一个内核缓冲区，并且该内核缓冲区以及它前面的内核缓冲区都是空闲的；否则，函数就会报错。在进一步描述函数binder_delete_free_buffer的实现之前，我们假设binder_buffer结构体prev和next分别指向要删除的内核缓冲区的前面一个内核缓冲区和后面一个内核缓冲区。

为了方便描述，我们假设binder_buffer结构体buffer、prev和next都是横跨在两个虚拟地址页面上的。第5行和第6行定义了两个变量free_page_start和free_page_end，并且将它们的值都设置为1，表示要释放binder_buffer结构体buffer所横跨的第一个虚拟地址页面和第二个虚拟地址页面所对应的物理页面。接下来会根据实际情况来调整变量free_page_start和free_page_end的值，以便可以正确地删除binder_buffer结构体buffer。

第11行到第16行的if语句块检查binder_buffer结构体buffer和prev的位置关系。如果binder_buffer结构体buffer的第一个虚拟地址页面和binder_buffer结构体prev的第二个虚拟地址页面是同一个页面，即第11行的if语句为true，那么binder_buffer结构体buffer所在的第一个虚拟地址页面所对应的物理页面就不可以释放，因此，第12行将变量free_page_start的值设置为0。如果binder_buffer结构体buffer的第二个虚拟地址页面和binder_buffer结构体prev的第二个虚拟地址页面也是同一个页面，即第13行的if语句为true，那么binder_buffer结构体buffer所在的第二个虚拟地址页面所对应的物理页面也不可以释放，因此，第14行也将变量free_page_end的值设置为0。这两种情况表明binder_buffer结构体buffer和prev同时位于一个虚拟地址页面中，如图5-13所示。

![图5-13　要删除的binder_buffer结构体和前一个binder_buffer结构体位于同一个虚拟地址页面](pic/2020-11-28-16-38-38.png)

第21行到第27行的if语句块检查binder_buffer结构体buffer和next的位置关系。如果binder_buffer结构体buffer的第二个虚拟地址页面和binder_buffer结构体next的第一个虚拟地址页面是同一个页面，即第21行的if语句为true，那么binder_buffer结构体buffer所在的第二个虚拟地址页面所对应的物理页面就不可以释放，因此，第22行将变量free_page_end的值设置为0。如果binder_buffer结构体buffer的第一个虚拟地址页面和binder_buffer结构体next的第一个虚拟地址页面也是同一个页面，即第23行的if语句为true，那么binder_buffer结构体buffer所在的第一个虚拟地址页面所对应的物理页面也不可以释放，因此，第25行也将变量free_page_start的值设置为0。这两种情况表明binder_buffer结构体buffer和next同时位于一个虚拟地址页面中，如图5-14所示。

![图5-14　要删除的binder_buffer结构体和后一个binder_buffer结构体位于同一个虚拟地址页面](pic/2020-11-28-16-39-21.png)

调整好变量free_page_start和free_page_end的值后，第29行首先将binder_buffer结构体buffer所描述的内核缓冲区从目标进程proc的内核缓冲区列表中删除，接着第30行的if语句检查是否需要释放binder_buffer结构体buffer所占用的物理页面。如果变量free_page_start或者free_page_end的值有一个等于1，那么第32行就需要调用函数binder_update_page_range来释放它所在的虚拟地址页面所对应的物理页面。变量free_page_start、free_page_end的值与要释放的物理页面的对应关系如表5-1所示。

![表5-1　变量free_page_start、free_page_end的值与要释放的物理页面的对应关系](pic/2020-11-28-16-40-17.png)

#### .1.5.3　查询内核缓冲区
在前面的5.1.5.2小节中提到，当一个进程使用完成一个内核缓冲区之后，它就会主动使用命令协议BC_FREE_BUFFER来通知Binder驱动程序释放内核缓冲区所对应的物理页面。然而，进程只知道要释放的内核缓冲区的用户空间地址，而Binder驱动程序需要知道用来描述该内核缓冲区的一个binder_buffer结构体，然后才可以释放它所占用的物理页面。因此，Binder驱动程序提供了函数binder_buffer_lookup根据一个用户空间地址来查询一个内核缓冲区，它的实现如下所示。

```cpp
static struct binder_buffer *binder_buffer_lookup(
	struct binder_proc *proc, void __user *user_ptr)
{
	struct rb_node *n = proc->allocated_buffers.rb_node;
	struct binder_buffer *buffer;
	struct binder_buffer *kern_ptr;

	kern_ptr = user_ptr - proc->user_buffer_offset
		- offsetof(struct binder_buffer, data);

	while (n) {
		buffer = rb_entry(n, struct binder_buffer, rb_node);
		BUG_ON(buffer->free);

		if (kern_ptr < buffer)
			n = n->rb_left;
		else if (kern_ptr > buffer)
			n = n->rb_right;
		else
			return buffer;
	}
	return NULL;
}
```
Binder驱动程序将一个内核缓冲区的数据传递给目标进程时，它只把数据缓冲区的用户地址传递给目标进程，即将一个binder_buffer结构体的成员变量data所指向的一块数据缓冲区的用户地址传递给目标进程。了解了这个背景知识之后，我们就可以知道，参数user_ptr是一个用户空间地址，并且它指向一个binder_buffer结构体的成员变量data的地址。

第8行和第9行中的子表达式user_ptr-offsetof(struct binder_buffer, data)用来计算一个binder_buffer结构体的用户空间地址，接着再减去目标进程proc的成员变量user_buffer_offset，就得到用户空间地址user_ptr所对应的binder_buffer结构体的内核空间地址了，最后将它保存在变量kern_ptr中。

前面计算得到的binder_buffer结构体的内核空间地址不一定指向一个有效的内核缓冲区，因此，函数就需要对它进行验证。只有验证通过后，才可以将它返回给调用者。在前面的5.1.1小节中介绍进程结构体binder_proc时提到，一个进程的已经分配物理页面的内核缓冲区，是以它的内核空间地址作为关键字保存在进程的已分配内核缓冲区红黑树allocated_buffers中的，因此，如果函数能够根据前面计算得到的binder_buffer结构体的内核空间地址在这个红黑树中找到一个对应的节点，那么就说明该binder_buffer结构体是指向一个有效的内核缓冲区的。第11行到第21行的while循环便是在目标进程proc的已分配内核缓冲区红黑树allocated_buffers中查找与内核空间地址kern_ptr对应的节点。如果能找到，那么第20行就将该节点所对应的一个binder_buffer结构体返回给调用者；否则，第22行就返回一个NULL值给调用者，表示找不到与用户空间地址user_ptr对应的内核缓冲区。

至此，我们就分析完成Binder驱动程序的基础知识了。接下来，我们继续分析应用程序框架层中的Binder进程间通信库的实现。

